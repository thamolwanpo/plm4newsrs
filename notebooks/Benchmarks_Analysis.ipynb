{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "673b5462",
   "metadata": {},
   "source": [
    "# Recommendation System Benchmark Analysis\n",
    "\n",
    "This notebook analyzes the performance of recommendation models under different conditions:\n",
    "- **Clean model**: Trained on clean data\n",
    "- **Poisoned model**: Trained on poisoned data\n",
    "- **Unlearned models**: Models that underwent unlearning (First Order and Gradient Ascent methods)\n",
    " \n",
    "We'll focus on metrics related to fake item detection and manipulation across different benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a89078a",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde89fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better-looking plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Create directories for saving tables and plots if they don't exist\n",
    "Path(\"tables\").mkdir(exist_ok=True)\n",
    "Path(\"plots\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60fc537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Finetune shape: (96, 18)\n",
      "Frozen shape: (96, 18)\n",
      "Combined shape: (192, 18)\n",
      "\n",
      "Model variants: {'finetune': 96, 'frozen': 96}\n",
      "\n",
      "Columns: ['model', 'benchmark', 'AUC', 'MRR', 'NDCG@5', 'NDCG@10', 'Recall@5', 'Recall@10', 'MC@5', 'MC@10', 'MC@20', 'avg_fake_in_top_10', 'avg_fake_in_top_20', 'users_with_fake_pct_top_10', 'users_with_fake_pct_top_20', 'avg_fake_ratio_top_10', 'avg_fake_ratio_top_20', 'model_variant']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>benchmark</th>\n",
       "      <th>AUC</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>MC@5</th>\n",
       "      <th>MC@10</th>\n",
       "      <th>MC@20</th>\n",
       "      <th>avg_fake_in_top_10</th>\n",
       "      <th>avg_fake_in_top_20</th>\n",
       "      <th>users_with_fake_pct_top_10</th>\n",
       "      <th>users_with_fake_pct_top_20</th>\n",
       "      <th>avg_fake_ratio_top_10</th>\n",
       "      <th>avg_fake_ratio_top_20</th>\n",
       "      <th>model_variant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clean-epoch=06-val_auc=0.8807</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>0.682974</td>\n",
       "      <td>0.152745</td>\n",
       "      <td>0.146443</td>\n",
       "      <td>0.190852</td>\n",
       "      <td>0.268012</td>\n",
       "      <td>0.406340</td>\n",
       "      <td>0.760807</td>\n",
       "      <td>0.623919</td>\n",
       "      <td>0.624063</td>\n",
       "      <td>6.239193</td>\n",
       "      <td>12.481268</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.623919</td>\n",
       "      <td>0.624063</td>\n",
       "      <td>finetune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clean-epoch=06-val_auc=0.8807</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "      <td>0.755733</td>\n",
       "      <td>0.261504</td>\n",
       "      <td>0.257802</td>\n",
       "      <td>0.311864</td>\n",
       "      <td>0.381107</td>\n",
       "      <td>0.547231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>finetune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean-epoch=06-val_auc=0.8807</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "      <td>0.717679</td>\n",
       "      <td>0.211042</td>\n",
       "      <td>0.203929</td>\n",
       "      <td>0.257625</td>\n",
       "      <td>0.319218</td>\n",
       "      <td>0.488599</td>\n",
       "      <td>0.538111</td>\n",
       "      <td>0.486319</td>\n",
       "      <td>0.545277</td>\n",
       "      <td>4.863192</td>\n",
       "      <td>10.905537</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.486319</td>\n",
       "      <td>0.545277</td>\n",
       "      <td>finetune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unlearned-first_order-ratio-0.01-trial-2</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>0.474696</td>\n",
       "      <td>0.072814</td>\n",
       "      <td>0.046258</td>\n",
       "      <td>0.068532</td>\n",
       "      <td>0.086455</td>\n",
       "      <td>0.158501</td>\n",
       "      <td>0.530259</td>\n",
       "      <td>0.408646</td>\n",
       "      <td>0.509510</td>\n",
       "      <td>4.086455</td>\n",
       "      <td>10.190202</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.408646</td>\n",
       "      <td>0.509510</td>\n",
       "      <td>finetune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unlearned-first_order-ratio-0.01-trial-2</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "      <td>0.496444</td>\n",
       "      <td>0.073914</td>\n",
       "      <td>0.036851</td>\n",
       "      <td>0.061733</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>0.140065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>finetune</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model            benchmark       AUC  \\\n",
       "0             clean-epoch=06-val_auc=0.8807   benchmark_honeypot  0.682974   \n",
       "1             clean-epoch=06-val_auc=0.8807  benchmark_real_only  0.755733   \n",
       "2             clean-epoch=06-val_auc=0.8807      benchmark_mixed  0.717679   \n",
       "3  unlearned-first_order-ratio-0.01-trial-2   benchmark_honeypot  0.474696   \n",
       "4  unlearned-first_order-ratio-0.01-trial-2  benchmark_real_only  0.496444   \n",
       "\n",
       "        MRR    NDCG@5   NDCG@10  Recall@5  Recall@10      MC@5     MC@10  \\\n",
       "0  0.152745  0.146443  0.190852  0.268012   0.406340  0.760807  0.623919   \n",
       "1  0.261504  0.257802  0.311864  0.381107   0.547231  0.000000  0.000000   \n",
       "2  0.211042  0.203929  0.257625  0.319218   0.488599  0.538111  0.486319   \n",
       "3  0.072814  0.046258  0.068532  0.086455   0.158501  0.530259  0.408646   \n",
       "4  0.073914  0.036851  0.061733  0.061889   0.140065  0.000000  0.000000   \n",
       "\n",
       "      MC@20  avg_fake_in_top_10  avg_fake_in_top_20  \\\n",
       "0  0.624063            6.239193           12.481268   \n",
       "1  0.000000            0.000000            0.000000   \n",
       "2  0.545277            4.863192           10.905537   \n",
       "3  0.509510            4.086455           10.190202   \n",
       "4  0.000000            0.000000            0.000000   \n",
       "\n",
       "   users_with_fake_pct_top_10  users_with_fake_pct_top_20  \\\n",
       "0                       100.0                       100.0   \n",
       "1                         0.0                         0.0   \n",
       "2                       100.0                       100.0   \n",
       "3                       100.0                       100.0   \n",
       "4                         0.0                         0.0   \n",
       "\n",
       "   avg_fake_ratio_top_10  avg_fake_ratio_top_20 model_variant  \n",
       "0               0.623919               0.624063      finetune  \n",
       "1               0.000000               0.000000      finetune  \n",
       "2               0.486319               0.545277      finetune  \n",
       "3               0.408646               0.509510      finetune  \n",
       "4               0.000000               0.000000      finetune  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from both CSV files\n",
    "\n",
    "df_finetune = pd.read_csv('/Users/ploymel/Documents/plm4newsrs/outputs/politifact/naml_model/bert_finetune/results/evaluation_summary.csv')  # Replace with your actual finetune CSV filename\n",
    "df_frozen = pd.read_csv('/Users/ploymel/Documents/plm4newsrs/outputs/politifact/naml_model/bert_frozen/results/evaluation_summary.csv')      # Replace with your actual frozen CSV filename\n",
    "\n",
    "# Add a column to distinguish between finetune and frozen\n",
    "df_finetune['model_variant'] = 'finetune'\n",
    "df_frozen['model_variant'] = 'frozen'\n",
    "\n",
    "# Combine both dataframes\n",
    "df = pd.concat([df_finetune, df_frozen], ignore_index=True)\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Finetune shape: {df_finetune.shape}\")\n",
    "print(f\"Frozen shape: {df_frozen.shape}\")\n",
    "print(f\"Combined shape: {df.shape}\")\n",
    "print(f\"\\nModel variants: {df['model_variant'].value_counts().to_dict()}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9bcc9e",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7304610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model types found:\n",
      "model_type\n",
      "unlearned    180\n",
      "clean          6\n",
      "poisoned       6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unlearning methods found:\n",
      "unlearning_method\n",
      "first_order        90\n",
      "gradient_ascent    90\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def parse_model_info(model_name):\n",
    "    \"\"\"Extract model type, method, ratio, and trial from model name\"\"\"\n",
    "    if 'clean' in model_name:\n",
    "        return 'clean', None, None, None\n",
    "    elif 'poisoned' in model_name:\n",
    "        return 'poisoned', None, None, None\n",
    "    elif 'unlearned' in model_name:\n",
    "        parts = model_name.split('-')\n",
    "        method = parts[1]  # e.g., 'first_order' or 'gradient_ascent'\n",
    "        ratio = None\n",
    "        trial = None\n",
    "        \n",
    "        for i, part in enumerate(parts):\n",
    "            if part == 'ratio' and i+1 < len(parts):\n",
    "                ratio = float(parts[i+1])\n",
    "            elif part == 'trial' and i+1 < len(parts):\n",
    "                trial = int(parts[i+1])\n",
    "        \n",
    "        return 'unlearned', method, ratio, trial\n",
    "    else:\n",
    "        return 'unknown', None, None, None\n",
    "\n",
    "# Apply parsing\n",
    "df[['model_type', 'unlearning_method', 'unlearning_ratio', 'trial']] = df['model'].apply(\n",
    "    lambda x: pd.Series(parse_model_info(x))\n",
    ")\n",
    "\n",
    "print(\"Model types found:\")\n",
    "print(df['model_type'].value_counts())\n",
    "print(\"\\nUnlearning methods found:\")\n",
    "print(df['unlearning_method'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d090d",
   "metadata": {},
   "source": [
    "## 3. Define Metric Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e819abc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric Groups:\n",
      "\n",
      "Performance Metrics:\n",
      "  - AUC\n",
      "  - MRR\n",
      "  - NDCG@5\n",
      "  - NDCG@10\n",
      "  - Recall@5\n",
      "  - Recall@10\n",
      "\n",
      "Manipulation Detection Metrics:\n",
      "  - MC@5\n",
      "  - MC@10\n",
      "  - MC@20\n",
      "\n",
      "Average Fake Items:\n",
      "  - avg_fake_in_top_10\n",
      "  - avg_fake_in_top_20\n",
      "\n",
      "User Coverage Metrics:\n",
      "  - users_with_fake_pct_top_10\n",
      "  - users_with_fake_pct_top_20\n",
      "\n",
      "Fake Ratio Metrics:\n",
      "  - avg_fake_ratio_top_10\n",
      "  - avg_fake_ratio_top_20\n"
     ]
    }
   ],
   "source": [
    "# Group metrics by category\n",
    "metric_groups = {\n",
    "    'Performance Metrics': ['AUC', 'MRR', 'NDCG@5', 'NDCG@10', 'Recall@5', 'Recall@10'],\n",
    "    'Manipulation Detection Metrics': ['MC@5', 'MC@10', 'MC@20'],\n",
    "    'Average Fake Items': ['avg_fake_in_top_10', 'avg_fake_in_top_20'],\n",
    "    'User Coverage Metrics': ['users_with_fake_pct_top_10', 'users_with_fake_pct_top_20'],\n",
    "    'Fake Ratio Metrics': ['avg_fake_ratio_top_10', 'avg_fake_ratio_top_20']\n",
    "}\n",
    "\n",
    "print(\"Metric Groups:\")\n",
    "for group, metrics in metric_groups.items():\n",
    "    print(f\"\\n{group}:\")\n",
    "    for metric in metrics:\n",
    "        print(f\"  - {metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499941b8",
   "metadata": {},
   "source": [
    "## 4. Aggregate Trials for Unlearned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b25a5dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original data shape: (192, 22)\n",
      "Aggregated data shape: (72, 22)\n",
      "\n",
      "Model variants distribution:\n",
      "model_variant\n",
      "finetune    36\n",
      "frozen      36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Aggregated models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model_variant</th>\n",
       "      <th>unlearning_method</th>\n",
       "      <th>unlearning_ratio</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>unlearned-first_order-ratio-0.01-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>unlearned-first_order-ratio-0.01-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>unlearned-first_order-ratio-0.01-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>unlearned-first_order-ratio-0.01-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unlearned-first_order-ratio-0.01-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>unlearned-first_order-ratio-0.01-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>unlearned-first_order-ratio-0.05-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>unlearned-first_order-ratio-0.05-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>unlearned-first_order-ratio-0.05-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>unlearned-first_order-ratio-0.05-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>unlearned-first_order-ratio-0.05-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>unlearned-first_order-ratio-0.05-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>unlearned-first_order-ratio-0.1-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>unlearned-first_order-ratio-0.1-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>unlearned-first_order-ratio-0.1-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>unlearned-first_order-ratio-0.1-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>unlearned-first_order-ratio-0.1-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>unlearned-first_order-ratio-0.1-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>unlearned-first_order-ratio-0.2-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>unlearned-first_order-ratio-0.2-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>unlearned-first_order-ratio-0.2-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>unlearned-first_order-ratio-0.2-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>unlearned-first_order-ratio-0.2-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>unlearned-first_order-ratio-0.2-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>unlearned-first_order-ratio-0.3-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>unlearned-first_order-ratio-0.3-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>unlearned-first_order-ratio-0.3-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>unlearned-first_order-ratio-0.3-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>unlearned-first_order-ratio-0.3-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>unlearned-first_order-ratio-0.3-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.01-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.01-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.01-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.01-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.01-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.01-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.01</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.05-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.05-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.05-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.05-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.05-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.05-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.05</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.1-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.1-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.1-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.1-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.1-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.1-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.10</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.2-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.2-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.2-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.2-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.2-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.2-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.20</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.3-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.3-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_honeypot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.3-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.3-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.3-avg</td>\n",
       "      <td>finetune</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>unlearned-gradient_ascent-ratio-0.3-avg</td>\n",
       "      <td>frozen</td>\n",
       "      <td>gradient_ascent</td>\n",
       "      <td>0.30</td>\n",
       "      <td>benchmark_real_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model model_variant unlearning_method  \\\n",
       "12      unlearned-first_order-ratio-0.01-avg      finetune       first_order   \n",
       "13      unlearned-first_order-ratio-0.01-avg        frozen       first_order   \n",
       "14      unlearned-first_order-ratio-0.01-avg      finetune       first_order   \n",
       "15      unlearned-first_order-ratio-0.01-avg        frozen       first_order   \n",
       "16      unlearned-first_order-ratio-0.01-avg      finetune       first_order   \n",
       "17      unlearned-first_order-ratio-0.01-avg        frozen       first_order   \n",
       "18      unlearned-first_order-ratio-0.05-avg      finetune       first_order   \n",
       "19      unlearned-first_order-ratio-0.05-avg        frozen       first_order   \n",
       "20      unlearned-first_order-ratio-0.05-avg      finetune       first_order   \n",
       "21      unlearned-first_order-ratio-0.05-avg        frozen       first_order   \n",
       "22      unlearned-first_order-ratio-0.05-avg      finetune       first_order   \n",
       "23      unlearned-first_order-ratio-0.05-avg        frozen       first_order   \n",
       "24       unlearned-first_order-ratio-0.1-avg      finetune       first_order   \n",
       "25       unlearned-first_order-ratio-0.1-avg        frozen       first_order   \n",
       "26       unlearned-first_order-ratio-0.1-avg      finetune       first_order   \n",
       "27       unlearned-first_order-ratio-0.1-avg        frozen       first_order   \n",
       "28       unlearned-first_order-ratio-0.1-avg      finetune       first_order   \n",
       "29       unlearned-first_order-ratio-0.1-avg        frozen       first_order   \n",
       "30       unlearned-first_order-ratio-0.2-avg      finetune       first_order   \n",
       "31       unlearned-first_order-ratio-0.2-avg        frozen       first_order   \n",
       "32       unlearned-first_order-ratio-0.2-avg      finetune       first_order   \n",
       "33       unlearned-first_order-ratio-0.2-avg        frozen       first_order   \n",
       "34       unlearned-first_order-ratio-0.2-avg      finetune       first_order   \n",
       "35       unlearned-first_order-ratio-0.2-avg        frozen       first_order   \n",
       "36       unlearned-first_order-ratio-0.3-avg      finetune       first_order   \n",
       "37       unlearned-first_order-ratio-0.3-avg        frozen       first_order   \n",
       "38       unlearned-first_order-ratio-0.3-avg      finetune       first_order   \n",
       "39       unlearned-first_order-ratio-0.3-avg        frozen       first_order   \n",
       "40       unlearned-first_order-ratio-0.3-avg      finetune       first_order   \n",
       "41       unlearned-first_order-ratio-0.3-avg        frozen       first_order   \n",
       "42  unlearned-gradient_ascent-ratio-0.01-avg      finetune   gradient_ascent   \n",
       "43  unlearned-gradient_ascent-ratio-0.01-avg        frozen   gradient_ascent   \n",
       "44  unlearned-gradient_ascent-ratio-0.01-avg      finetune   gradient_ascent   \n",
       "45  unlearned-gradient_ascent-ratio-0.01-avg        frozen   gradient_ascent   \n",
       "46  unlearned-gradient_ascent-ratio-0.01-avg      finetune   gradient_ascent   \n",
       "47  unlearned-gradient_ascent-ratio-0.01-avg        frozen   gradient_ascent   \n",
       "48  unlearned-gradient_ascent-ratio-0.05-avg      finetune   gradient_ascent   \n",
       "49  unlearned-gradient_ascent-ratio-0.05-avg        frozen   gradient_ascent   \n",
       "50  unlearned-gradient_ascent-ratio-0.05-avg      finetune   gradient_ascent   \n",
       "51  unlearned-gradient_ascent-ratio-0.05-avg        frozen   gradient_ascent   \n",
       "52  unlearned-gradient_ascent-ratio-0.05-avg      finetune   gradient_ascent   \n",
       "53  unlearned-gradient_ascent-ratio-0.05-avg        frozen   gradient_ascent   \n",
       "54   unlearned-gradient_ascent-ratio-0.1-avg      finetune   gradient_ascent   \n",
       "55   unlearned-gradient_ascent-ratio-0.1-avg        frozen   gradient_ascent   \n",
       "56   unlearned-gradient_ascent-ratio-0.1-avg      finetune   gradient_ascent   \n",
       "57   unlearned-gradient_ascent-ratio-0.1-avg        frozen   gradient_ascent   \n",
       "58   unlearned-gradient_ascent-ratio-0.1-avg      finetune   gradient_ascent   \n",
       "59   unlearned-gradient_ascent-ratio-0.1-avg        frozen   gradient_ascent   \n",
       "60   unlearned-gradient_ascent-ratio-0.2-avg      finetune   gradient_ascent   \n",
       "61   unlearned-gradient_ascent-ratio-0.2-avg        frozen   gradient_ascent   \n",
       "62   unlearned-gradient_ascent-ratio-0.2-avg      finetune   gradient_ascent   \n",
       "63   unlearned-gradient_ascent-ratio-0.2-avg        frozen   gradient_ascent   \n",
       "64   unlearned-gradient_ascent-ratio-0.2-avg      finetune   gradient_ascent   \n",
       "65   unlearned-gradient_ascent-ratio-0.2-avg        frozen   gradient_ascent   \n",
       "66   unlearned-gradient_ascent-ratio-0.3-avg      finetune   gradient_ascent   \n",
       "67   unlearned-gradient_ascent-ratio-0.3-avg        frozen   gradient_ascent   \n",
       "68   unlearned-gradient_ascent-ratio-0.3-avg      finetune   gradient_ascent   \n",
       "69   unlearned-gradient_ascent-ratio-0.3-avg        frozen   gradient_ascent   \n",
       "70   unlearned-gradient_ascent-ratio-0.3-avg      finetune   gradient_ascent   \n",
       "71   unlearned-gradient_ascent-ratio-0.3-avg        frozen   gradient_ascent   \n",
       "\n",
       "    unlearning_ratio            benchmark  \n",
       "12              0.01   benchmark_honeypot  \n",
       "13              0.01   benchmark_honeypot  \n",
       "14              0.01      benchmark_mixed  \n",
       "15              0.01      benchmark_mixed  \n",
       "16              0.01  benchmark_real_only  \n",
       "17              0.01  benchmark_real_only  \n",
       "18              0.05   benchmark_honeypot  \n",
       "19              0.05   benchmark_honeypot  \n",
       "20              0.05      benchmark_mixed  \n",
       "21              0.05      benchmark_mixed  \n",
       "22              0.05  benchmark_real_only  \n",
       "23              0.05  benchmark_real_only  \n",
       "24              0.10   benchmark_honeypot  \n",
       "25              0.10   benchmark_honeypot  \n",
       "26              0.10      benchmark_mixed  \n",
       "27              0.10      benchmark_mixed  \n",
       "28              0.10  benchmark_real_only  \n",
       "29              0.10  benchmark_real_only  \n",
       "30              0.20   benchmark_honeypot  \n",
       "31              0.20   benchmark_honeypot  \n",
       "32              0.20      benchmark_mixed  \n",
       "33              0.20      benchmark_mixed  \n",
       "34              0.20  benchmark_real_only  \n",
       "35              0.20  benchmark_real_only  \n",
       "36              0.30   benchmark_honeypot  \n",
       "37              0.30   benchmark_honeypot  \n",
       "38              0.30      benchmark_mixed  \n",
       "39              0.30      benchmark_mixed  \n",
       "40              0.30  benchmark_real_only  \n",
       "41              0.30  benchmark_real_only  \n",
       "42              0.01   benchmark_honeypot  \n",
       "43              0.01   benchmark_honeypot  \n",
       "44              0.01      benchmark_mixed  \n",
       "45              0.01      benchmark_mixed  \n",
       "46              0.01  benchmark_real_only  \n",
       "47              0.01  benchmark_real_only  \n",
       "48              0.05   benchmark_honeypot  \n",
       "49              0.05   benchmark_honeypot  \n",
       "50              0.05      benchmark_mixed  \n",
       "51              0.05      benchmark_mixed  \n",
       "52              0.05  benchmark_real_only  \n",
       "53              0.05  benchmark_real_only  \n",
       "54              0.10   benchmark_honeypot  \n",
       "55              0.10   benchmark_honeypot  \n",
       "56              0.10      benchmark_mixed  \n",
       "57              0.10      benchmark_mixed  \n",
       "58              0.10  benchmark_real_only  \n",
       "59              0.10  benchmark_real_only  \n",
       "60              0.20   benchmark_honeypot  \n",
       "61              0.20   benchmark_honeypot  \n",
       "62              0.20      benchmark_mixed  \n",
       "63              0.20      benchmark_mixed  \n",
       "64              0.20  benchmark_real_only  \n",
       "65              0.20  benchmark_real_only  \n",
       "66              0.30   benchmark_honeypot  \n",
       "67              0.30   benchmark_honeypot  \n",
       "68              0.30      benchmark_mixed  \n",
       "69              0.30      benchmark_mixed  \n",
       "70              0.30  benchmark_real_only  \n",
       "71              0.30  benchmark_real_only  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aggregate_trials(df):\n",
    "    \"\"\"Average results across different trials for unlearned models\"\"\"\n",
    "    \n",
    "    # Separate unlearned models from others\n",
    "    unlearned_df = df[df['model_type'] == 'unlearned'].copy()\n",
    "    other_df = df[df['model_type'] != 'unlearned'].copy()\n",
    "    \n",
    "    if len(unlearned_df) > 0:\n",
    "        # Group by everything except trial and average\n",
    "        group_cols = ['model_type', 'unlearning_method', 'unlearning_ratio', 'benchmark', 'model_variant']\n",
    "        \n",
    "        # Get numeric columns to average (exclude columns that are already in group_cols)\n",
    "        numeric_cols = [col for col in df.select_dtypes(include=[np.number]).columns \n",
    "                       if col not in group_cols]\n",
    "        \n",
    "        # Group and aggregate\n",
    "        unlearned_agg = unlearned_df.groupby(group_cols)[numeric_cols].mean().reset_index()\n",
    "        \n",
    "        # Add a model name for aggregated data\n",
    "        unlearned_agg['model'] = unlearned_agg.apply(\n",
    "            lambda row: f\"unlearned-{row['unlearning_method']}-ratio-{row['unlearning_ratio']}-avg\", \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Add trial column as NaN to match other_df structure\n",
    "        unlearned_agg['trial'] = np.nan\n",
    "        \n",
    "        # Combine back\n",
    "        result_df = pd.concat([other_df, unlearned_agg], ignore_index=True)\n",
    "    else:\n",
    "        result_df = other_df\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "df_agg = aggregate_trials(df)\n",
    "\n",
    "print(f\"\\nOriginal data shape: {df.shape}\")\n",
    "print(f\"Aggregated data shape: {df_agg.shape}\")\n",
    "print(f\"\\nModel variants distribution:\")\n",
    "print(df_agg['model_variant'].value_counts())\n",
    "print(f\"\\nAggregated models:\")\n",
    "df_agg[df_agg['model_type'] == 'unlearned'][['model', 'model_variant', 'unlearning_method', 'unlearning_ratio', 'benchmark']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7247c2ce",
   "metadata": {},
   "source": [
    "## 5. Create Summary Tables by Metric Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a03126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Creating summary table for: Performance Metrics\n",
      "============================================================\n",
      "Saved to: tables/performance_metrics.csv\n",
      "Shape: (72, 12)\n",
      "\n",
      "============================================================\n",
      "Creating summary table for: Manipulation Detection Metrics\n",
      "============================================================\n",
      "Saved to: tables/manipulation_detection_metrics.csv\n",
      "Shape: (72, 9)\n",
      "\n",
      "============================================================\n",
      "Creating summary table for: Average Fake Items\n",
      "============================================================\n",
      "Saved to: tables/average_fake_items.csv\n",
      "Shape: (72, 8)\n",
      "\n",
      "============================================================\n",
      "Creating summary table for: User Coverage Metrics\n",
      "============================================================\n",
      "Saved to: tables/user_coverage_metrics.csv\n",
      "Shape: (72, 8)\n",
      "\n",
      "============================================================\n",
      "Creating summary table for: Fake Ratio Metrics\n",
      "============================================================\n",
      "Saved to: tables/fake_ratio_metrics.csv\n",
      "Shape: (72, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create summary tables for each metric group\n",
    "summary_tables = {}\n",
    "\n",
    "for group_name, metrics in metric_groups.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Creating summary table for: {group_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Select relevant columns\n",
    "    cols_to_select = ['model', 'benchmark', 'model_type', 'model_variant', 'unlearning_method', 'unlearning_ratio'] + metrics\n",
    "    \n",
    "    # Filter for non-trial data (aggregated + clean + poisoned)\n",
    "    mask = (df_agg['model_type'].isin(['clean', 'poisoned'])) | \\\n",
    "           ((df_agg['model_type'] == 'unlearned') & (df_agg['trial'].isna()))\n",
    "    \n",
    "    summary_df = df_agg[mask][cols_to_select].copy()\n",
    "    \n",
    "    # Sort for better readability\n",
    "    summary_df = summary_df.sort_values(['benchmark', 'model_variant', 'model_type', 'unlearning_method', 'unlearning_ratio'])\n",
    "    \n",
    "    # Save to CSV\n",
    "    filename = f\"tables/{group_name.lower().replace(' ', '_')}.csv\"\n",
    "    summary_df.to_csv(filename, index=False)\n",
    "    \n",
    "    summary_tables[group_name] = summary_df\n",
    "    \n",
    "    print(f\"Saved to: {filename}\")\n",
    "    print(f\"Shape: {summary_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26752daf",
   "metadata": {},
   "source": [
    "## 6. Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fead2af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_plot(df_agg, metric, benchmark_type, output_dir='plots'):\n",
    "    \"\"\"\n",
    "    Create a comparison plot for a specific metric and benchmark type\n",
    "    Compares finetune vs frozen models\n",
    "    Excludes real_only benchmark as those values are always 0 for manipulation metrics\n",
    "    \"\"\"\n",
    "    # Filter data\n",
    "    plot_data = df_agg[df_agg['benchmark'] == benchmark_type].copy()\n",
    "    \n",
    "    # Skip if no data\n",
    "    if len(plot_data) == 0:\n",
    "        print(f\"No data for {metric} on {benchmark_type}\")\n",
    "        return\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Define line styles for model variants\n",
    "    line_styles = {'finetune': '-', 'frozen': '--'}\n",
    "    variant_labels = {'finetune': 'Finetune', 'frozen': 'Frozen'}\n",
    "    \n",
    "    # Process each model variant separately\n",
    "    for variant in ['finetune', 'frozen']:\n",
    "        variant_data = plot_data[plot_data['model_variant'] == variant]\n",
    "        \n",
    "        if len(variant_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Prepare data for plotting\n",
    "        clean_data = variant_data[variant_data['model_type'] == 'clean']\n",
    "        poisoned_data = variant_data[variant_data['model_type'] == 'poisoned']\n",
    "        unlearned_data = variant_data[variant_data['model_type'] == 'unlearned']\n",
    "        \n",
    "        # Plot clean and poisoned as horizontal lines\n",
    "        if len(clean_data) > 0:\n",
    "            clean_value = clean_data[metric].values[0]\n",
    "            ax.axhline(y=clean_value, color='green', linestyle=line_styles[variant], \n",
    "                      linewidth=2.5, label=f'Clean - {variant_labels[variant]}', alpha=0.7)\n",
    "        \n",
    "        if len(poisoned_data) > 0:\n",
    "            poisoned_value = poisoned_data[metric].values[0]\n",
    "            ax.axhline(y=poisoned_value, color='red', linestyle=line_styles[variant], \n",
    "                      linewidth=2.5, label=f'Poisoned - {variant_labels[variant]}', alpha=0.7)\n",
    "        \n",
    "        # Plot unlearned models by method\n",
    "        if len(unlearned_data) > 0:\n",
    "            methods = unlearned_data['unlearning_method'].unique()\n",
    "            colors = {'first_order': 'blue', 'gradient_ascent': 'orange'}\n",
    "            markers = {'first_order': 'o', 'gradient_ascent': 's'}\n",
    "            \n",
    "            for method in methods:\n",
    "                method_data = unlearned_data[unlearned_data['unlearning_method'] == method]\n",
    "                method_data = method_data.sort_values('unlearning_ratio')\n",
    "                \n",
    "                ax.plot(method_data['unlearning_ratio'], method_data[metric], \n",
    "                       marker=markers.get(method, 'o'), \n",
    "                       color=colors.get(method, 'purple'),\n",
    "                       linestyle=line_styles[variant],\n",
    "                       linewidth=2.5, markersize=8,\n",
    "                       label=f'{method.replace(\"_\", \" \").title()} - {variant_labels[variant]}',\n",
    "                       alpha=0.8)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Unlearning Ratio', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric, fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{metric} Comparison (Finetune vs Frozen) - {benchmark_type.replace(\"_\", \" \").title()}', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', fontsize=9, framealpha=0.9, ncol=2)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Save plot\n",
    "    filename = f\"{output_dir}/{metric}_{benchmark_type}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8dd3aa",
   "metadata": {},
   "source": [
    "## 7. Generate All Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bee4203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating comparison plots...\n",
      "============================================================\n",
      "\n",
      "Processing metric: MC@5\n",
      "Saved: plots/MC@5_benchmark_honeypot.png\n",
      "Saved: plots/MC@5_benchmark_mixed.png\n",
      "\n",
      "Processing metric: MC@10\n",
      "Saved: plots/MC@10_benchmark_honeypot.png\n",
      "Saved: plots/MC@10_benchmark_mixed.png\n",
      "\n",
      "Processing metric: MC@20\n",
      "Saved: plots/MC@20_benchmark_honeypot.png\n",
      "Saved: plots/MC@20_benchmark_mixed.png\n",
      "\n",
      "Processing metric: avg_fake_in_top_10\n",
      "Saved: plots/avg_fake_in_top_10_benchmark_honeypot.png\n",
      "Saved: plots/avg_fake_in_top_10_benchmark_mixed.png\n",
      "\n",
      "Processing metric: avg_fake_in_top_20\n",
      "Saved: plots/avg_fake_in_top_20_benchmark_honeypot.png\n",
      "Saved: plots/avg_fake_in_top_20_benchmark_mixed.png\n",
      "\n",
      "Processing metric: users_with_fake_pct_top_10\n",
      "Saved: plots/users_with_fake_pct_top_10_benchmark_honeypot.png\n",
      "Saved: plots/users_with_fake_pct_top_10_benchmark_mixed.png\n",
      "\n",
      "Processing metric: users_with_fake_pct_top_20\n",
      "Saved: plots/users_with_fake_pct_top_20_benchmark_honeypot.png\n",
      "Saved: plots/users_with_fake_pct_top_20_benchmark_mixed.png\n",
      "\n",
      "Processing metric: avg_fake_ratio_top_10\n",
      "Saved: plots/avg_fake_ratio_top_10_benchmark_honeypot.png\n",
      "Saved: plots/avg_fake_ratio_top_10_benchmark_mixed.png\n",
      "\n",
      "Processing metric: avg_fake_ratio_top_20\n",
      "Saved: plots/avg_fake_ratio_top_20_benchmark_honeypot.png\n",
      "Saved: plots/avg_fake_ratio_top_20_benchmark_mixed.png\n",
      "\n",
      "============================================================\n",
      "All plots generated successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Metrics to plot (excluding real_only benchmark)\n",
    "fake_detection_metrics = [\n",
    "    'MC@5', 'MC@10', 'MC@20',\n",
    "    'avg_fake_in_top_10', 'avg_fake_in_top_20',\n",
    "    'users_with_fake_pct_top_10', 'users_with_fake_pct_top_20',\n",
    "    'avg_fake_ratio_top_10', 'avg_fake_ratio_top_20'\n",
    "]\n",
    "\n",
    "# Benchmarks to plot (excluding real_only)\n",
    "benchmarks_to_plot = ['benchmark_honeypot', 'benchmark_mixed']\n",
    "\n",
    "print(\"\\nGenerating comparison plots...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric in fake_detection_metrics:\n",
    "    print(f\"\\nProcessing metric: {metric}\")\n",
    "    for benchmark in benchmarks_to_plot:\n",
    "        create_comparison_plot(df_agg, metric, benchmark)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All plots generated successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78266820",
   "metadata": {},
   "source": [
    "## 7b. Generate Performance Metric Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "268a2bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating performance metric plots...\n",
      "============================================================\n",
      "\n",
      "Processing metric: AUC\n",
      "Saved: plots/AUC_benchmark_honeypot.png\n",
      "Saved: plots/AUC_benchmark_mixed.png\n",
      "Saved: plots/AUC_benchmark_real_only.png\n",
      "\n",
      "Processing metric: MRR\n",
      "Saved: plots/MRR_benchmark_honeypot.png\n",
      "Saved: plots/MRR_benchmark_mixed.png\n",
      "Saved: plots/MRR_benchmark_real_only.png\n",
      "\n",
      "Processing metric: NDCG@5\n",
      "Saved: plots/NDCG@5_benchmark_honeypot.png\n",
      "Saved: plots/NDCG@5_benchmark_mixed.png\n",
      "Saved: plots/NDCG@5_benchmark_real_only.png\n",
      "\n",
      "Processing metric: NDCG@10\n",
      "Saved: plots/NDCG@10_benchmark_honeypot.png\n",
      "Saved: plots/NDCG@10_benchmark_mixed.png\n",
      "Saved: plots/NDCG@10_benchmark_real_only.png\n",
      "\n",
      "Processing metric: Recall@5\n",
      "Saved: plots/Recall@5_benchmark_honeypot.png\n",
      "Saved: plots/Recall@5_benchmark_mixed.png\n",
      "Saved: plots/Recall@5_benchmark_real_only.png\n",
      "\n",
      "Processing metric: Recall@10\n",
      "Saved: plots/Recall@10_benchmark_honeypot.png\n",
      "Saved: plots/Recall@10_benchmark_mixed.png\n",
      "Saved: plots/Recall@10_benchmark_real_only.png\n",
      "\n",
      "============================================================\n",
      "All performance metric plots generated!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Performance metrics to plot (include all benchmarks including real_only for these)\n",
    "performance_metrics = ['AUC', 'MRR', 'NDCG@5', 'NDCG@10', 'Recall@5', 'Recall@10']\n",
    "\n",
    "# All benchmarks for performance metrics\n",
    "all_benchmarks = ['benchmark_honeypot', 'benchmark_mixed', 'benchmark_real_only']\n",
    "\n",
    "print(\"\\nGenerating performance metric plots...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric in performance_metrics:\n",
    "    print(f\"\\nProcessing metric: {metric}\")\n",
    "    for benchmark in all_benchmarks:\n",
    "        create_comparison_plot(df_agg, metric, benchmark)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All performance metric plots generated!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842c749",
   "metadata": {},
   "source": [
    "## 8. Create Combined Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57a120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_plot(df_agg, metrics_list, benchmark_type, title, output_dir='plots'):\n",
    "    \"\"\"Create a multi-panel plot for related metrics comparing finetune vs frozen\"\"\"\n",
    "    \n",
    "    n_metrics = len(metrics_list)\n",
    "    n_cols = 3\n",
    "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5*n_rows))\n",
    "    axes = axes.flatten() if n_metrics > 1 else [axes]\n",
    "    \n",
    "    # Define line styles for model variants\n",
    "    line_styles = {'finetune': '-', 'frozen': '--'}\n",
    "    variant_labels = {'finetune': 'Finetune', 'frozen': 'Frozen'}\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_list):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Filter data\n",
    "        plot_data = df_agg[df_agg['benchmark'] == benchmark_type].copy()\n",
    "        \n",
    "        if len(plot_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Process each model variant\n",
    "        for variant in ['finetune', 'frozen']:\n",
    "            variant_data = plot_data[plot_data['model_variant'] == variant]\n",
    "            \n",
    "            if len(variant_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Prepare data\n",
    "            clean_data = variant_data[variant_data['model_type'] == 'clean']\n",
    "            poisoned_data = variant_data[variant_data['model_type'] == 'poisoned']\n",
    "            unlearned_data = variant_data[variant_data['model_type'] == 'unlearned']\n",
    "            \n",
    "            # Plot reference lines\n",
    "            if len(clean_data) > 0:\n",
    "                ax.axhline(y=clean_data[metric].values[0], color='green', \n",
    "                          linestyle=line_styles[variant], linewidth=1.5, \n",
    "                          label=f'Clean-{variant_labels[variant]}', alpha=0.7)\n",
    "            \n",
    "            if len(poisoned_data) > 0:\n",
    "                ax.axhline(y=poisoned_data[metric].values[0], color='red', \n",
    "                          linestyle=line_styles[variant], linewidth=1.5, \n",
    "                          label=f'Poisoned-{variant_labels[variant]}', alpha=0.7)\n",
    "            \n",
    "            # Plot unlearned models\n",
    "            if len(unlearned_data) > 0:\n",
    "                methods = unlearned_data['unlearning_method'].unique()\n",
    "                colors = {'first_order': 'blue', 'gradient_ascent': 'orange'}\n",
    "                markers = {'first_order': 'o', 'gradient_ascent': 's'}\n",
    "                \n",
    "                for method in methods:\n",
    "                    method_data = unlearned_data[unlearned_data['unlearning_method'] == method]\n",
    "                    method_data = method_data.sort_values('unlearning_ratio')\n",
    "                    \n",
    "                    ax.plot(method_data['unlearning_ratio'], method_data[metric], \n",
    "                           marker=markers.get(method, 'o'), \n",
    "                           color=colors.get(method, 'purple'),\n",
    "                           linestyle=line_styles[variant],\n",
    "                           linewidth=2, markersize=6,\n",
    "                           label=f'{method.replace(\"_\", \" \").title()}-{variant_labels[variant]}',\n",
    "                           alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Unlearning Ratio', fontsize=10)\n",
    "        ax.set_ylabel(metric, fontsize=10)\n",
    "        ax.set_title(metric, fontsize=11, fontweight='bold')\n",
    "        ax.legend(loc='best', fontsize=7, ncol=2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(n_metrics, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(f'{title} (Finetune vs Frozen) - {benchmark_type.replace(\"_\", \" \").title()}', \n",
    "                 fontsize=16, fontweight='bold', y=1.00)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    filename = f\"{output_dir}/combined_{title.lower().replace(' ', '_')}_{benchmark_type}.png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved combined plot: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c96c014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating combined plots...\n",
      "============================================================\n",
      "Saved combined plot: plots/combined_manipulation_detection_benchmark_honeypot.png\n",
      "Saved combined plot: plots/combined_manipulation_detection_benchmark_mixed.png\n",
      "Saved combined plot: plots/combined_average_fake_items_benchmark_honeypot.png\n",
      "Saved combined plot: plots/combined_average_fake_items_benchmark_mixed.png\n",
      "Saved combined plot: plots/combined_user_coverage_benchmark_honeypot.png\n",
      "Saved combined plot: plots/combined_user_coverage_benchmark_mixed.png\n",
      "Saved combined plot: plots/combined_fake_ratios_benchmark_honeypot.png\n",
      "Saved combined plot: plots/combined_fake_ratios_benchmark_mixed.png\n",
      "\n",
      "All combined plots generated!\n"
     ]
    }
   ],
   "source": [
    "# Generate combined plots for each metric group\n",
    "print(\"\\nGenerating combined plots...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metric_groups_to_plot = {\n",
    "    'Manipulation Detection': ['MC@5', 'MC@10', 'MC@20'],\n",
    "    'Average Fake Items': ['avg_fake_in_top_10', 'avg_fake_in_top_20'],\n",
    "    'User Coverage': ['users_with_fake_pct_top_10', 'users_with_fake_pct_top_20'],\n",
    "    'Fake Ratios': ['avg_fake_ratio_top_10', 'avg_fake_ratio_top_20']\n",
    "}\n",
    "\n",
    "for title, metrics in metric_groups_to_plot.items():\n",
    "    for benchmark in benchmarks_to_plot:\n",
    "        create_combined_plot(df_agg, metrics, benchmark, title)\n",
    "\n",
    "print(\"\\nAll combined plots generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553208ec",
   "metadata": {},
   "source": [
    "## 9. Find Best Unlearning Ratio for Each Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f364ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_ratio_for_method(df_agg, method, benchmark_type, model_variant):\n",
    "    \"\"\"\n",
    "    Find the best unlearning ratio based on AUC on benchmark_real_only.\n",
    "    This measures true recommendation utility without attack contamination.\n",
    "    \"\"\"\n",
    "    # Filter for this method, benchmark_real_only, and variant\n",
    "    method_data = df_agg[\n",
    "        (df_agg['unlearning_method'] == method) & \n",
    "        (df_agg['benchmark'] == 'benchmark_real_only') &  # Use real_only for selection\n",
    "        (df_agg['model_variant'] == model_variant) &\n",
    "        (df_agg['trial'].isna())\n",
    "    ].copy()\n",
    "    \n",
    "    if len(method_data) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    # Get clean model's AUC as reference\n",
    "    clean_data = df_agg[\n",
    "        (df_agg['model_type'] == 'clean') & \n",
    "        (df_agg['benchmark'] == 'benchmark_real_only') &\n",
    "        (df_agg['model_variant'] == model_variant)\n",
    "    ]\n",
    "    \n",
    "    if len(clean_data) == 0:\n",
    "        # Fallback: just pick the ratio with highest AUC\n",
    "        best_ratio = method_data.loc[method_data['AUC'].idxmax(), 'unlearning_ratio']\n",
    "    else:\n",
    "        # Find ratio with AUC closest to clean model\n",
    "        clean_auc = clean_data['AUC'].values[0]\n",
    "        method_data['auc_distance'] = abs(method_data['AUC'] - clean_auc)\n",
    "        best_ratio = method_data.loc[method_data['auc_distance'].idxmin(), 'unlearning_ratio']\n",
    "    \n",
    "    # Now get the full row for this ratio from the original benchmark_type\n",
    "    best_row = df_agg[\n",
    "        (df_agg['unlearning_method'] == method) & \n",
    "        (df_agg['benchmark'] == benchmark_type) &  # Get data for the actual benchmark being analyzed\n",
    "        (df_agg['model_variant'] == model_variant) &\n",
    "        (df_agg['unlearning_ratio'] == best_ratio) &\n",
    "        (df_agg['trial'].isna())\n",
    "    ]\n",
    "    \n",
    "    if len(best_row) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    return best_ratio, best_row.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a6f2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINDING BEST UNLEARNING RATIOS\n",
      "================================================================================\n",
      "\n",
      "============================================================\n",
      "Benchmark: Benchmark Honeypot\n",
      "============================================================\n",
      "\n",
      "  Model Variant: FINETUNE\n",
      "  --------------------------------------------------------\n",
      "\n",
      "  First Order:\n",
      "    Best Ratio: 0.1\n",
      "    Sample metrics at best ratio:\n",
      "      MC@5: 0.6446\n",
      "      MC@10: 0.6208\n",
      "      avg_fake_in_top_10: 6.2085\n",
      "\n",
      "  Gradient Ascent:\n",
      "    Best Ratio: 0.05\n",
      "    Sample metrics at best ratio:\n",
      "      MC@5: 0.6957\n",
      "      MC@10: 0.6921\n",
      "      avg_fake_in_top_10: 6.9212\n",
      "\n",
      "  Model Variant: FROZEN\n",
      "  --------------------------------------------------------\n",
      "\n",
      "  First Order:\n",
      "    Best Ratio: 0.2\n",
      "    Sample metrics at best ratio:\n",
      "      MC@5: 0.6780\n",
      "      MC@10: 0.6049\n",
      "      avg_fake_in_top_10: 6.0884\n",
      "\n",
      "  Gradient Ascent:\n",
      "    Best Ratio: 0.01\n",
      "    Sample metrics at best ratio:\n",
      "      MC@5: 0.6110\n",
      "      MC@10: 0.6172\n",
      "      avg_fake_in_top_10: 6.1720\n",
      "\n",
      "============================================================\n",
      "Benchmark: Benchmark Mixed\n",
      "============================================================\n",
      "\n",
      "  Model Variant: FINETUNE\n",
      "  --------------------------------------------------------\n",
      "\n",
      "  First Order:\n",
      "    Best Ratio: 0.1\n",
      "    Sample metrics at best ratio:\n",
      "      MC@5: 0.4860\n",
      "      MC@10: 0.4927\n",
      "      avg_fake_in_top_10: 4.9273\n",
      "\n",
      "  Gradient Ascent:\n",
      "    Best Ratio: 0.05\n",
      "    Sample metrics at best ratio:\n",
      "      MC@5: 0.5887\n",
      "      MC@10: 0.5803\n",
      "      avg_fake_in_top_10: 5.8035\n",
      "\n",
      "  Model Variant: FROZEN\n",
      "  --------------------------------------------------------\n",
      "\n",
      "  First Order:\n",
      "    Best Ratio: 0.2\n",
      "    Sample metrics at best ratio:\n",
      "      MC@5: 0.5752\n",
      "      MC@10: 0.5569\n",
      "      avg_fake_in_top_10: 5.6221\n",
      "\n",
      "  Gradient Ascent:\n",
      "    Best Ratio: 0.01\n",
      "    Sample metrics at best ratio:\n",
      "      MC@5: 0.5865\n",
      "      MC@10: 0.5969\n",
      "      avg_fake_in_top_10: 5.9685\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINDING BEST UNLEARNING RATIOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ALL metrics to analyze (both performance and manipulation)\n",
    "all_analysis_metrics = [\n",
    "    # Performance metrics\n",
    "    'AUC', 'MRR', 'NDCG@5', 'NDCG@10', 'Recall@5', 'Recall@10',\n",
    "    # Manipulation detection metrics\n",
    "    'MC@5', 'MC@10', 'MC@20',\n",
    "    'avg_fake_in_top_10', 'avg_fake_in_top_20',\n",
    "    'users_with_fake_pct_top_10', 'users_with_fake_pct_top_20',\n",
    "    'avg_fake_ratio_top_10', 'avg_fake_ratio_top_20'\n",
    "]\n",
    "\n",
    "# Metrics for plotting (excluding real_only benchmark)\n",
    "fake_detection_metrics = [\n",
    "    'MC@5', 'MC@10', 'MC@20',\n",
    "    'avg_fake_in_top_10', 'avg_fake_in_top_20',\n",
    "    'users_with_fake_pct_top_10', 'users_with_fake_pct_top_20',\n",
    "    'avg_fake_ratio_top_10', 'avg_fake_ratio_top_20'\n",
    "]\n",
    "\n",
    "best_ratios = {}\n",
    "\n",
    "for benchmark in benchmarks_to_plot:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Benchmark: {benchmark.replace('_', ' ').title()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    best_ratios[benchmark] = {}\n",
    "    \n",
    "    # Iterate over model variants\n",
    "    for variant in ['finetune', 'frozen']:\n",
    "        print(f\"\\n  Model Variant: {variant.upper()}\")\n",
    "        print(f\"  {'-'*56}\")\n",
    "        \n",
    "        best_ratios[benchmark][variant] = {}\n",
    "        \n",
    "        # Get unlearning methods for this variant\n",
    "        unlearned_data = df_agg[\n",
    "            (df_agg['model_type'] == 'unlearned') & \n",
    "            (df_agg['benchmark'] == benchmark) &\n",
    "            (df_agg['model_variant'] == variant) &\n",
    "            (df_agg['trial'].isna())\n",
    "        ]\n",
    "        \n",
    "        if len(unlearned_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        methods = unlearned_data['unlearning_method'].unique()\n",
    "        \n",
    "        for method in methods:\n",
    "            print(f\"\\n  {method.replace('_', ' ').title()}:\")\n",
    "            \n",
    "            best_ratio, best_row = find_best_ratio_for_method(\n",
    "                df_agg, method, benchmark, variant\n",
    "            )\n",
    "            \n",
    "            if best_ratio is not None:\n",
    "                print(f\"    Best Ratio: {best_ratio}\")\n",
    "                print(f\"    Sample metrics at best ratio:\")\n",
    "                for metric in ['MC@5', 'MC@10', 'avg_fake_in_top_10']:\n",
    "                    print(f\"      {metric}: {best_row[metric]:.4f}\")\n",
    "                \n",
    "                best_ratios[benchmark][variant][method] = {\n",
    "                    'ratio': best_ratio,\n",
    "                    'data': best_row\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aa3189",
   "metadata": {},
   "source": [
    "## 10. Calculate Unlearning Impact (Change from Poisoned Model)\n",
    "```\n",
    "Recovery % = (Poisoned Value - Unlearned Value) / (Poisoned Value - Clean Value) × 100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2216d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unlearning_impact(df_agg, best_ratios, metrics):\n",
    "    \"\"\"\n",
    "    Calculate how much unlearning changed the results compared to poisoned model.\n",
    "    Reports both absolute change and percentage change.\n",
    "    Compares finetune vs frozen as well.\n",
    "    \n",
    "    Special handling for honeypot benchmark:\n",
    "    - Performance metrics: Lower is better (don't recommend fakes)\n",
    "    - Manipulation metrics: Lower is better (same as other benchmarks)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define which metrics are \"higher is better\" (for mixed/real_only benchmarks)\n",
    "    performance_metrics = ['AUC', 'MRR', 'NDCG@5', 'NDCG@10', 'Recall@5', 'Recall@10']\n",
    "    \n",
    "    impact_results = []\n",
    "    \n",
    "    for benchmark in benchmarks_to_plot:\n",
    "        if benchmark not in best_ratios:\n",
    "            continue\n",
    "        \n",
    "        for variant in ['finetune', 'frozen']:\n",
    "            if variant not in best_ratios[benchmark]:\n",
    "                continue\n",
    "            \n",
    "            # Get poisoned baseline for this variant\n",
    "            poisoned_data = df_agg[\n",
    "                (df_agg['model_type'] == 'poisoned') & \n",
    "                (df_agg['benchmark'] == benchmark) &\n",
    "                (df_agg['model_variant'] == variant)\n",
    "            ]\n",
    "            \n",
    "            # Get clean baseline for reference\n",
    "            clean_data = df_agg[\n",
    "                (df_agg['model_type'] == 'clean') & \n",
    "                (df_agg['benchmark'] == benchmark) &\n",
    "                (df_agg['model_variant'] == variant)\n",
    "            ]\n",
    "            \n",
    "            if len(poisoned_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            poisoned_row = poisoned_data.iloc[0]\n",
    "            clean_row = clean_data.iloc[0] if len(clean_data) > 0 else None\n",
    "            \n",
    "            for method, method_info in best_ratios[benchmark][variant].items():\n",
    "                best_ratio = method_info['ratio']\n",
    "                unlearned_row = method_info['data']\n",
    "                \n",
    "                for metric in metrics:\n",
    "                    poisoned_val = poisoned_row[metric]\n",
    "                    unlearned_val = unlearned_row[metric]\n",
    "                    clean_val = clean_row[metric] if clean_row is not None else None\n",
    "                    \n",
    "                    # Calculate changes\n",
    "                    absolute_change = unlearned_val - poisoned_val\n",
    "                    \n",
    "                    if poisoned_val != 0:\n",
    "                        percent_change = (absolute_change / poisoned_val) * 100\n",
    "                    else:\n",
    "                        percent_change = 0 if absolute_change == 0 else float('inf')\n",
    "                    \n",
    "                    # Calculate recovery towards clean (if clean exists)\n",
    "                    recovery_pct = None\n",
    "                    if clean_val is not None and poisoned_val != clean_val:\n",
    "                        # Special handling for honeypot benchmark\n",
    "                        if benchmark == 'benchmark_honeypot' and metric in performance_metrics:\n",
    "                            # On honeypot, lower performance = better (means not recommending fakes)\n",
    "                            # We want to move from poisoned DOWN toward clean (or toward 0)\n",
    "                            total_gap = poisoned_val - clean_val  # Positive gap (going down)\n",
    "                            recovered_gap = poisoned_val - unlearned_val  # Positive if we moved down\n",
    "                        else:\n",
    "                            # Normal case: \n",
    "                            # - For performance metrics on mixed/real_only: higher is better\n",
    "                            # - For manipulation metrics on all benchmarks: lower is better\n",
    "                            total_gap = clean_val - poisoned_val  # Gap we want to close\n",
    "                            recovered_gap = unlearned_val - poisoned_val  # How much we moved\n",
    "                        \n",
    "                        recovery_pct = (recovered_gap / total_gap) * 100 if total_gap != 0 else 0\n",
    "                    \n",
    "                    impact_results.append({\n",
    "                        'benchmark': benchmark,\n",
    "                        'model_variant': variant,\n",
    "                        'method': method,\n",
    "                        'best_ratio': best_ratio,\n",
    "                        'metric': metric,\n",
    "                        'clean_value': clean_val,\n",
    "                        'poisoned_value': poisoned_val,\n",
    "                        'unlearned_value': unlearned_val,\n",
    "                        'absolute_change': absolute_change,\n",
    "                        'percent_change': percent_change,\n",
    "                        'recovery_pct': recovery_pct\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(impact_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd7f8a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CALCULATING UNLEARNING IMPACT\n",
      "================================================================================\n",
      "\n",
      "Saved impact analysis to: tables/unlearning_impact_analysis.csv\n",
      "\n",
      "Impact Analysis Summary:\n",
      "Shape: (120, 11)\n",
      "\n",
      "Sample results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benchmark</th>\n",
       "      <th>model_variant</th>\n",
       "      <th>method</th>\n",
       "      <th>best_ratio</th>\n",
       "      <th>metric</th>\n",
       "      <th>clean_value</th>\n",
       "      <th>poisoned_value</th>\n",
       "      <th>unlearned_value</th>\n",
       "      <th>absolute_change</th>\n",
       "      <th>percent_change</th>\n",
       "      <th>recovery_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>AUC</td>\n",
       "      <td>0.682974</td>\n",
       "      <td>0.623013</td>\n",
       "      <td>0.624149</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.182267</td>\n",
       "      <td>1.893809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MRR</td>\n",
       "      <td>0.152745</td>\n",
       "      <td>0.149383</td>\n",
       "      <td>0.166241</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>11.285408</td>\n",
       "      <td>501.340324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NDCG@5</td>\n",
       "      <td>0.146443</td>\n",
       "      <td>0.117218</td>\n",
       "      <td>0.143585</td>\n",
       "      <td>0.026366</td>\n",
       "      <td>22.493196</td>\n",
       "      <td>90.220008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NDCG@10</td>\n",
       "      <td>0.190852</td>\n",
       "      <td>0.160588</td>\n",
       "      <td>0.184509</td>\n",
       "      <td>0.023921</td>\n",
       "      <td>14.896039</td>\n",
       "      <td>79.042375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Recall@5</td>\n",
       "      <td>0.268012</td>\n",
       "      <td>0.175793</td>\n",
       "      <td>0.213256</td>\n",
       "      <td>0.037464</td>\n",
       "      <td>21.311475</td>\n",
       "      <td>40.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Recall@10</td>\n",
       "      <td>0.406340</td>\n",
       "      <td>0.308357</td>\n",
       "      <td>0.341018</td>\n",
       "      <td>0.032661</td>\n",
       "      <td>10.591900</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MC@5</td>\n",
       "      <td>0.760807</td>\n",
       "      <td>0.689914</td>\n",
       "      <td>0.644573</td>\n",
       "      <td>-0.045341</td>\n",
       "      <td>-6.571986</td>\n",
       "      <td>-63.956640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MC@10</td>\n",
       "      <td>0.623919</td>\n",
       "      <td>0.692507</td>\n",
       "      <td>0.620845</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-10.348176</td>\n",
       "      <td>104.481793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>MC@20</td>\n",
       "      <td>0.624063</td>\n",
       "      <td>0.628386</td>\n",
       "      <td>0.632853</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.710846</td>\n",
       "      <td>-103.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>avg_fake_in_top_10</td>\n",
       "      <td>6.239193</td>\n",
       "      <td>6.925072</td>\n",
       "      <td>6.208453</td>\n",
       "      <td>-0.716619</td>\n",
       "      <td>-10.348176</td>\n",
       "      <td>104.481793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>avg_fake_in_top_20</td>\n",
       "      <td>12.481268</td>\n",
       "      <td>12.567723</td>\n",
       "      <td>12.657061</td>\n",
       "      <td>0.089337</td>\n",
       "      <td>0.710846</td>\n",
       "      <td>-103.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>users_with_fake_pct_top_10</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>users_with_fake_pct_top_20</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>avg_fake_ratio_top_10</td>\n",
       "      <td>0.623919</td>\n",
       "      <td>0.692507</td>\n",
       "      <td>0.620845</td>\n",
       "      <td>-0.071662</td>\n",
       "      <td>-10.348176</td>\n",
       "      <td>104.481793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>benchmark_honeypot</td>\n",
       "      <td>finetune</td>\n",
       "      <td>first_order</td>\n",
       "      <td>0.1</td>\n",
       "      <td>avg_fake_ratio_top_20</td>\n",
       "      <td>0.624063</td>\n",
       "      <td>0.628386</td>\n",
       "      <td>0.632853</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.710846</td>\n",
       "      <td>-103.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             benchmark model_variant       method  best_ratio  \\\n",
       "0   benchmark_honeypot      finetune  first_order         0.1   \n",
       "1   benchmark_honeypot      finetune  first_order         0.1   \n",
       "2   benchmark_honeypot      finetune  first_order         0.1   \n",
       "3   benchmark_honeypot      finetune  first_order         0.1   \n",
       "4   benchmark_honeypot      finetune  first_order         0.1   \n",
       "5   benchmark_honeypot      finetune  first_order         0.1   \n",
       "6   benchmark_honeypot      finetune  first_order         0.1   \n",
       "7   benchmark_honeypot      finetune  first_order         0.1   \n",
       "8   benchmark_honeypot      finetune  first_order         0.1   \n",
       "9   benchmark_honeypot      finetune  first_order         0.1   \n",
       "10  benchmark_honeypot      finetune  first_order         0.1   \n",
       "11  benchmark_honeypot      finetune  first_order         0.1   \n",
       "12  benchmark_honeypot      finetune  first_order         0.1   \n",
       "13  benchmark_honeypot      finetune  first_order         0.1   \n",
       "14  benchmark_honeypot      finetune  first_order         0.1   \n",
       "\n",
       "                        metric  clean_value  poisoned_value  unlearned_value  \\\n",
       "0                          AUC     0.682974        0.623013         0.624149   \n",
       "1                          MRR     0.152745        0.149383         0.166241   \n",
       "2                       NDCG@5     0.146443        0.117218         0.143585   \n",
       "3                      NDCG@10     0.190852        0.160588         0.184509   \n",
       "4                     Recall@5     0.268012        0.175793         0.213256   \n",
       "5                    Recall@10     0.406340        0.308357         0.341018   \n",
       "6                         MC@5     0.760807        0.689914         0.644573   \n",
       "7                        MC@10     0.623919        0.692507         0.620845   \n",
       "8                        MC@20     0.624063        0.628386         0.632853   \n",
       "9           avg_fake_in_top_10     6.239193        6.925072         6.208453   \n",
       "10          avg_fake_in_top_20    12.481268       12.567723        12.657061   \n",
       "11  users_with_fake_pct_top_10   100.000000      100.000000       100.000000   \n",
       "12  users_with_fake_pct_top_20   100.000000      100.000000       100.000000   \n",
       "13       avg_fake_ratio_top_10     0.623919        0.692507         0.620845   \n",
       "14       avg_fake_ratio_top_20     0.624063        0.628386         0.632853   \n",
       "\n",
       "    absolute_change  percent_change  recovery_pct  \n",
       "0          0.001136        0.182267      1.893809  \n",
       "1          0.016858       11.285408    501.340324  \n",
       "2          0.026366       22.493196     90.220008  \n",
       "3          0.023921       14.896039     79.042375  \n",
       "4          0.037464       21.311475     40.625000  \n",
       "5          0.032661       10.591900     33.333333  \n",
       "6         -0.045341       -6.571986    -63.956640  \n",
       "7         -0.071662      -10.348176    104.481793  \n",
       "8          0.004467        0.710846   -103.333333  \n",
       "9         -0.716619      -10.348176    104.481793  \n",
       "10         0.089337        0.710846   -103.333333  \n",
       "11         0.000000        0.000000           NaN  \n",
       "12         0.000000        0.000000           NaN  \n",
       "13        -0.071662      -10.348176    104.481793  \n",
       "14         0.004467        0.710846   -103.333333  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CALCULATING UNLEARNING IMPACT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "impact_df = calculate_unlearning_impact(df_agg, best_ratios, all_analysis_metrics)\n",
    "\n",
    "# Save the impact analysis\n",
    "impact_df.to_csv('tables/unlearning_impact_analysis.csv', index=False)\n",
    "print(\"\\nSaved impact analysis to: tables/unlearning_impact_analysis.csv\")\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nImpact Analysis Summary:\")\n",
    "print(f\"Shape: {impact_df.shape}\")\n",
    "print(f\"\\nSample results:\")\n",
    "impact_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003798d",
   "metadata": {},
   "source": [
    "## 11. Create Detailed Impact Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "518fff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "UNLEARNING IMPACT REPORT\n",
      "================================================================================\n",
      "\n",
      "This report shows how much unlearning (at best ratio) changed each metric\n",
      "compared to the poisoned model, and what % of the gap to clean was recovered.\n",
      "Results are shown separately for Finetune and Frozen models.\n",
      "================================================================================\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# BENCHMARK: Benchmark Honeypot\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Model Variant: FINETUNE\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: First Order\n",
      "Best Ratio: 0.1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Metric                         Clean        Poisoned     Unlearned    Change       % Change     Recovery %  \n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "AUC                            0.6830       0.6230       0.6241       +0.0011      +0.18%       1.89%       \n",
      "MRR                            0.1527       0.1494       0.1662       +0.0169      +11.29%      501.34%     \n",
      "NDCG@5                         0.1464       0.1172       0.1436       +0.0264      +22.49%      90.22%      \n",
      "NDCG@10                        0.1909       0.1606       0.1845       +0.0239      +14.90%      79.04%      \n",
      "Recall@5                       0.2680       0.1758       0.2133       +0.0375      +21.31%      40.63%      \n",
      "Recall@10                      0.4063       0.3084       0.3410       +0.0327      +10.59%      33.33%      \n",
      "MC@5                           0.7608       0.6899       0.6446       -0.0453      -6.57%       -63.96%     \n",
      "MC@10                          0.6239       0.6925       0.6208       -0.0717      -10.35%      104.48%     \n",
      "MC@20                          0.6241       0.6284       0.6329       +0.0045      +0.71%       -103.33%    \n",
      "avg_fake_in_top_10             6.2392       6.9251       6.2085       -0.7166      -10.35%      104.48%     \n",
      "avg_fake_in_top_20             12.4813      12.5677      12.6571      +0.0893      +0.71%       -103.33%    \n",
      "users_with_fake_pct_top_10     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "users_with_fake_pct_top_20     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "avg_fake_ratio_top_10          0.6239       0.6925       0.6208       -0.0717      -10.35%      104.48%     \n",
      "avg_fake_ratio_top_20          0.6241       0.6284       0.6329       +0.0045      +0.71%       -103.33%    \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: Gradient Ascent\n",
      "Best Ratio: 0.05\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Metric                         Clean        Poisoned     Unlearned    Change       % Change     Recovery %  \n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "AUC                            0.6830       0.6230       0.6204       -0.0026      -0.42%       -4.36%      \n",
      "MRR                            0.1527       0.1494       0.1510       +0.0016      +1.08%       48.15%      \n",
      "NDCG@5                         0.1464       0.1172       0.1214       +0.0042      +3.55%       14.22%      \n",
      "NDCG@10                        0.1909       0.1606       0.1624       +0.0018      +1.15%       6.09%       \n",
      "Recall@5                       0.2680       0.1758       0.1825       +0.0067      +3.83%       7.29%       \n",
      "Recall@10                      0.4063       0.3084       0.3084       +0.0000      +0.00%       -0.00%      \n",
      "MC@5                           0.7608       0.6899       0.6957       +0.0058      +0.84%       8.13%       \n",
      "MC@10                          0.6239       0.6925       0.6921       -0.0004      -0.06%       0.56%       \n",
      "MC@20                          0.6241       0.6284       0.6345       +0.0061      +0.97%       -141.11%    \n",
      "avg_fake_in_top_10             6.2392       6.9251       6.9212       -0.0038      -0.06%       0.56%       \n",
      "avg_fake_in_top_20             12.4813      12.5677      12.6897      +0.1220      +0.97%       -141.11%    \n",
      "users_with_fake_pct_top_10     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "users_with_fake_pct_top_20     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "avg_fake_ratio_top_10          0.6239       0.6925       0.6921       -0.0004      -0.06%       0.56%       \n",
      "avg_fake_ratio_top_20          0.6241       0.6284       0.6345       +0.0061      +0.97%       -141.11%    \n",
      "\n",
      "================================================================================\n",
      "Model Variant: FROZEN\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: First Order\n",
      "Best Ratio: 0.2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Metric                         Clean        Poisoned     Unlearned    Change       % Change     Recovery %  \n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "AUC                            0.5513       0.5268       0.5283       +0.0015      +0.29%       6.26%       \n",
      "MRR                            0.1356       0.0838       0.1874       +0.1036      +123.53%     200.22%     \n",
      "NDCG@5                         0.1087       0.0428       0.2202       +0.1773      +413.89%     269.33%     \n",
      "NDCG@10                        0.1269       0.0803       0.2407       +0.1604      +199.87%     344.21%     \n",
      "Recall@5                       0.1499       0.0663       0.4073       +0.3410      +514.49%     408.05%     \n",
      "Recall@10                      0.2075       0.1816       0.4717       +0.2901      +159.79%     1118.52%    \n",
      "MC@5                           0.4536       0.6121       0.6780       +0.0659      +10.77%      -41.58%     \n",
      "MC@10                          0.5470       0.6184       0.6049       -0.0135      -2.19%       18.95%      \n",
      "MC@20                          0.6163       0.5516       0.5823       +0.0307      +5.56%       47.44%      \n",
      "avg_fake_in_top_10             5.4697       6.1844       6.0884       -0.0961      -1.55%       13.44%      \n",
      "avg_fake_in_top_20             12.3256      11.0317      11.6446      +0.6129      +5.56%       47.36%      \n",
      "users_with_fake_pct_top_10     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "users_with_fake_pct_top_20     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "avg_fake_ratio_top_10          0.5470       0.6184       0.6088       -0.0096      -1.55%       13.44%      \n",
      "avg_fake_ratio_top_20          0.6163       0.5516       0.5822       +0.0306      +5.56%       47.36%      \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: Gradient Ascent\n",
      "Best Ratio: 0.01\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Metric                         Clean        Poisoned     Unlearned    Change       % Change     Recovery %  \n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "AUC                            0.5513       0.5268       0.5260       -0.0008      -0.15%       -3.21%      \n",
      "MRR                            0.1356       0.0838       0.0838       -0.0000      -0.06%       -0.09%      \n",
      "NDCG@5                         0.1087       0.0428       0.0436       +0.0007      +1.73%       1.13%       \n",
      "NDCG@10                        0.1269       0.0803       0.0797       -0.0005      -0.68%       -1.17%      \n",
      "Recall@5                       0.1499       0.0663       0.0682       +0.0019      +2.90%       2.30%       \n",
      "Recall@10                      0.2075       0.1816       0.1796       -0.0019      -1.06%       -7.41%      \n",
      "MC@5                           0.4536       0.6121       0.6110       -0.0012      -0.19%       0.73%       \n",
      "MC@10                          0.5470       0.6184       0.6172       -0.0012      -0.20%       1.75%       \n",
      "MC@20                          0.6163       0.5516       0.5508       -0.0008      -0.15%       -1.26%      \n",
      "avg_fake_in_top_10             5.4697       6.1844       6.1720       -0.0125      -0.20%       1.75%       \n",
      "avg_fake_in_top_20             12.3256      11.0317      11.0154      -0.0163      -0.15%       -1.26%      \n",
      "users_with_fake_pct_top_10     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "users_with_fake_pct_top_20     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "avg_fake_ratio_top_10          0.5470       0.6184       0.6172       -0.0012      -0.20%       1.75%       \n",
      "avg_fake_ratio_top_20          0.6163       0.5516       0.5508       -0.0008      -0.15%       -1.26%      \n",
      "\n",
      "\n",
      "################################################################################\n",
      "# BENCHMARK: Benchmark Mixed\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Model Variant: FINETUNE\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: First Order\n",
      "Best Ratio: 0.1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Metric                         Clean        Poisoned     Unlearned    Change       % Change     Recovery %  \n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "AUC                            0.7177       0.6083       0.6039       -0.0045      -0.74%       -4.09%      \n",
      "MRR                            0.2110       0.1530       0.1729       +0.0199      +13.00%      34.28%      \n",
      "NDCG@5                         0.2039       0.1344       0.1610       +0.0266      +19.80%      38.26%      \n",
      "NDCG@10                        0.2576       0.1899       0.1965       +0.0066      +3.49%       9.77%       \n",
      "Recall@5                       0.3192       0.2215       0.2497       +0.0282      +12.75%      28.89%      \n",
      "Recall@10                      0.4886       0.3941       0.3572       -0.0369      -9.37%       -39.08%     \n",
      "MC@5                           0.5381       0.5824       0.4860       -0.0964      -16.55%      217.65%     \n",
      "MC@10                          0.4863       0.5746       0.4927       -0.0819      -14.25%      92.74%      \n",
      "MC@20                          0.5453       0.5432       0.5291       -0.0141      -2.59%       -664.10%    \n",
      "avg_fake_in_top_10             4.8632       5.7459       4.9273       -0.8187      -14.25%      92.74%      \n",
      "avg_fake_in_top_20             10.9055      10.8632      10.5820      -0.2812      -2.59%       -664.10%    \n",
      "users_with_fake_pct_top_10     100.0000     100.0000     99.3485      -0.6515      -0.65%       nan%        \n",
      "users_with_fake_pct_top_20     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "avg_fake_ratio_top_10          0.4863       0.5746       0.4927       -0.0819      -14.25%      92.74%      \n",
      "avg_fake_ratio_top_20          0.5453       0.5432       0.5291       -0.0141      -2.59%       -664.10%    \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: Gradient Ascent\n",
      "Best Ratio: 0.05\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Metric                         Clean        Poisoned     Unlearned    Change       % Change     Recovery %  \n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "AUC                            0.7177       0.6083       0.6043       -0.0041      -0.67%       -3.71%      \n",
      "MRR                            0.2110       0.1530       0.1548       +0.0018      +1.18%       3.12%       \n",
      "NDCG@5                         0.2039       0.1344       0.1340       -0.0004      -0.26%       -0.51%      \n",
      "NDCG@10                        0.2576       0.1899       0.1906       +0.0007      +0.39%       1.08%       \n",
      "Recall@5                       0.3192       0.2215       0.2161       -0.0054      -2.45%       -5.56%      \n",
      "Recall@10                      0.4886       0.3941       0.3920       -0.0022      -0.55%       -2.30%      \n",
      "MC@5                           0.5381       0.5824       0.5887       +0.0063      +1.08%       -14.22%     \n",
      "MC@10                          0.4863       0.5746       0.5803       +0.0058      +1.00%       -6.52%      \n",
      "MC@20                          0.5453       0.5432       0.5488       +0.0056      +1.04%       266.67%     \n",
      "avg_fake_in_top_10             4.8632       5.7459       5.8035       +0.0575      +1.00%       -6.52%      \n",
      "avg_fake_in_top_20             10.9055      10.8632      10.9761      +0.1129      +1.04%       266.67%     \n",
      "users_with_fake_pct_top_10     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "users_with_fake_pct_top_20     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "avg_fake_ratio_top_10          0.4863       0.5746       0.5803       +0.0058      +1.00%       -6.52%      \n",
      "avg_fake_ratio_top_20          0.5453       0.5432       0.5488       +0.0056      +1.04%       266.67%     \n",
      "\n",
      "================================================================================\n",
      "Model Variant: FROZEN\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: First Order\n",
      "Best Ratio: 0.2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Metric                         Clean        Poisoned     Unlearned    Change       % Change     Recovery %  \n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "AUC                            0.6119       0.4321       0.4566       +0.0245      +5.66%       13.61%      \n",
      "MRR                            0.2030       0.0575       0.1516       +0.0940      +163.53%     64.62%      \n",
      "NDCG@5                         0.1879       0.0224       0.1858       +0.1634      +730.24%     98.75%      \n",
      "NDCG@10                        0.2142       0.0424       0.1988       +0.1564      +368.83%     91.05%      \n",
      "Recall@5                       0.2541       0.0423       0.3713       +0.3290      +776.92%     155.38%     \n",
      "Recall@10                      0.3388       0.1042       0.4126       +0.3084      +295.83%     131.48%     \n",
      "MC@5                           0.4293       0.5876       0.5752       -0.0124      -2.11%       7.82%       \n",
      "MC@10                          0.5355       0.5971       0.5569       -0.0402      -6.73%       65.26%      \n",
      "MC@20                          0.5940       0.5378       0.5480       +0.0103      +1.91%       18.26%      \n",
      "avg_fake_in_top_10             5.3550       5.9707       5.6221       -0.3485      -5.84%       56.61%      \n",
      "avg_fake_in_top_20             11.8795      10.7557      10.9609      +0.2052      +1.91%       18.26%      \n",
      "users_with_fake_pct_top_10     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "users_with_fake_pct_top_20     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "avg_fake_ratio_top_10          0.5355       0.5971       0.5622       -0.0349      -5.84%       56.61%      \n",
      "avg_fake_ratio_top_20          0.5940       0.5378       0.5480       +0.0103      +1.91%       18.26%      \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Method: Gradient Ascent\n",
      "Best Ratio: 0.01\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Metric                         Clean        Poisoned     Unlearned    Change       % Change     Recovery %  \n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "AUC                            0.6119       0.4321       0.4322       +0.0001      +0.02%       0.04%       \n",
      "MRR                            0.2030       0.0575       0.0577       +0.0002      +0.32%       0.13%       \n",
      "NDCG@5                         0.1879       0.0224       0.0225       +0.0002      +0.67%       0.09%       \n",
      "NDCG@10                        0.2142       0.0424       0.0426       +0.0002      +0.42%       0.10%       \n",
      "Recall@5                       0.2541       0.0423       0.0423       +0.0000      +0.00%       0.00%       \n",
      "Recall@10                      0.3388       0.1042       0.1042       +0.0000      +0.00%       0.00%       \n",
      "MC@5                           0.4293       0.5876       0.5865       -0.0011      -0.18%       0.69%       \n",
      "MC@10                          0.5355       0.5971       0.5969       -0.0002      -0.04%       0.35%       \n",
      "MC@20                          0.5940       0.5378       0.5375       -0.0003      -0.06%       -0.58%      \n",
      "avg_fake_in_top_10             5.3550       5.9707       5.9685       -0.0022      -0.04%       0.35%       \n",
      "avg_fake_in_top_20             11.8795      10.7557      10.7492      -0.0065      -0.06%       -0.58%      \n",
      "users_with_fake_pct_top_10     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "users_with_fake_pct_top_20     100.0000     100.0000     100.0000     +0.0000      +0.00%       nan%        \n",
      "avg_fake_ratio_top_10          0.5355       0.5971       0.5969       -0.0002      -0.04%       0.35%       \n",
      "avg_fake_ratio_top_20          0.5940       0.5378       0.5375       -0.0003      -0.06%       -0.58%      \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"UNLEARNING IMPACT REPORT\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThis report shows how much unlearning (at best ratio) changed each metric\")\n",
    "print(\"compared to the poisoned model, and what % of the gap to clean was recovered.\")\n",
    "print(\"Results are shown separately for Finetune and Frozen models.\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for benchmark in benchmarks_to_plot:\n",
    "    benchmark_impact = impact_df[impact_df['benchmark'] == benchmark]\n",
    "    \n",
    "    if len(benchmark_impact) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n\\n{'#'*80}\")\n",
    "    print(f\"# BENCHMARK: {benchmark.replace('_', ' ').title()}\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    variants = benchmark_impact['model_variant'].unique()\n",
    "    \n",
    "    for variant in variants:\n",
    "        variant_impact = benchmark_impact[benchmark_impact['model_variant'] == variant]\n",
    "        \n",
    "        if len(variant_impact) == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Model Variant: {variant.upper()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        methods = variant_impact['method'].unique()\n",
    "        \n",
    "        for method in methods:\n",
    "            method_impact = variant_impact[variant_impact['method'] == method]\n",
    "            \n",
    "            if len(method_impact) == 0:\n",
    "                continue\n",
    "            \n",
    "            best_ratio = method_impact['best_ratio'].iloc[0]\n",
    "            \n",
    "            print(f\"\\n{'-'*80}\")\n",
    "            print(f\"Method: {method.replace('_', ' ').title()}\")\n",
    "            print(f\"Best Ratio: {best_ratio}\")\n",
    "            print(f\"{'-'*80}\")\n",
    "            \n",
    "            print(f\"\\n{'Metric':<30} {'Clean':<12} {'Poisoned':<12} {'Unlearned':<12} {'Change':<12} {'% Change':<12} {'Recovery %':<12}\")\n",
    "            print(f\"{'-'*130}\")\n",
    "            \n",
    "            for _, row in method_impact.iterrows():\n",
    "                metric = row['metric']\n",
    "                clean_val = row['clean_value']\n",
    "                poisoned_val = row['poisoned_value']\n",
    "                unlearned_val = row['unlearned_value']\n",
    "                abs_change = row['absolute_change']\n",
    "                pct_change = row['percent_change']\n",
    "                recovery = row['recovery_pct']\n",
    "                \n",
    "                # Format values\n",
    "                clean_str = f\"{clean_val:.4f}\" if clean_val is not None else \"N/A\"\n",
    "                poisoned_str = f\"{poisoned_val:.4f}\"\n",
    "                unlearned_str = f\"{unlearned_val:.4f}\"\n",
    "                change_str = f\"{abs_change:+.4f}\"\n",
    "                pct_str = f\"{pct_change:+.2f}%\" if abs(pct_change) != float('inf') else \"N/A\"\n",
    "                recovery_str = f\"{recovery:.2f}%\" if recovery is not None else \"N/A\"\n",
    "                \n",
    "                print(f\"{metric:<30} {clean_str:<12} {poisoned_str:<12} {unlearned_str:<12} {change_str:<12} {pct_str:<12} {recovery_str:<12}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef19ecd",
   "metadata": {},
   "source": [
    "## 12. Visualize Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1b9d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_impact_visualization(impact_df, benchmark_type, output_dir='plots'):\n",
    "    \"\"\"Create visualization showing the impact of unlearning, comparing finetune vs frozen\"\"\"\n",
    "    \n",
    "    bench_data = impact_df[impact_df['benchmark'] == benchmark_type]\n",
    "    \n",
    "    if len(bench_data) == 0:\n",
    "        return\n",
    "    \n",
    "    variants = bench_data['model_variant'].unique()\n",
    "    methods = bench_data['method'].unique()\n",
    "    \n",
    "    # Create subplots: one row per variant, one column per method\n",
    "    fig, axes = plt.subplots(len(variants), len(methods), \n",
    "                             figsize=(8*len(methods), 6*len(variants)))\n",
    "    \n",
    "    # Handle single variant or method cases\n",
    "    if len(variants) == 1 and len(methods) == 1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif len(variants) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    elif len(methods) == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for v_idx, variant in enumerate(variants):\n",
    "        for m_idx, method in enumerate(methods):\n",
    "            ax = axes[v_idx, m_idx]\n",
    "            \n",
    "            # Get data for this variant and method\n",
    "            data = bench_data[\n",
    "                (bench_data['model_variant'] == variant) & \n",
    "                (bench_data['method'] == method)\n",
    "            ]\n",
    "            \n",
    "            if len(data) == 0:\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "            \n",
    "            # Prepare data for plotting\n",
    "            x = range(len(data))\n",
    "            metrics_list = data['metric'].tolist()\n",
    "            recovery_pcts = data['recovery_pct'].tolist()\n",
    "            \n",
    "            # Color based on recovery percentage\n",
    "            colors = ['green' if r and r > 50 else 'orange' if r and r > 0 else 'red' \n",
    "                      for r in recovery_pcts]\n",
    "            \n",
    "            bars = ax.barh(x, recovery_pcts, color=colors, alpha=0.7)\n",
    "            ax.set_yticks(x)\n",
    "            ax.set_yticklabels(metrics_list, fontsize=9)\n",
    "            ax.set_xlabel('Recovery Percentage (%)', fontsize=11, fontweight='bold')\n",
    "            \n",
    "            # Title shows both variant and method\n",
    "            title = f'{variant.upper()} - {method.replace(\"_\", \" \").title()}'\n",
    "            best_ratio = data['best_ratio'].iloc[0]\n",
    "            title += f'\\n(Best Ratio: {best_ratio})'\n",
    "            ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "            \n",
    "            ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "            ax.axvline(x=100, color='green', linestyle='--', linewidth=1, alpha=0.5, label='Full Recovery')\n",
    "            ax.grid(True, alpha=0.3, axis='x')\n",
    "            ax.legend(fontsize=8)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for i, (bar, val) in enumerate(zip(bars, recovery_pcts)):\n",
    "                if val is not None:\n",
    "                    ax.text(val, bar.get_y() + bar.get_height()/2, \n",
    "                           f'{val:.1f}%', \n",
    "                           va='center', ha='left' if val >= 0 else 'right',\n",
    "                           fontsize=8, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle(f'Unlearning Recovery Analysis (Finetune vs Frozen) - {benchmark_type.replace(\"_\", \" \").title()}',\n",
    "                 fontsize=16, fontweight='bold', y=1.00)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"{output_dir}/impact_recovery_{benchmark_type}.png\"\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved impact visualization: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdad7ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating impact visualizations...\n",
      "============================================================\n",
      "Saved impact visualization: plots/impact_recovery_benchmark_honeypot.png\n",
      "Saved impact visualization: plots/impact_recovery_benchmark_mixed.png\n",
      "\n",
      "All impact visualizations generated!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating impact visualizations...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for benchmark in benchmarks_to_plot:\n",
    "    create_impact_visualization(impact_df, benchmark)\n",
    "\n",
    "print(\"\\nAll impact visualizations generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7163ff00",
   "metadata": {},
   "source": [
    "## 13. Create Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "289cc22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_summary_comparison_table(impact_df):\n",
    "    \"\"\"Create a summary table comparing methods across all metrics, including finetune vs frozen\"\"\"\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for benchmark in impact_df['benchmark'].unique():\n",
    "        bench_data = impact_df[impact_df['benchmark'] == benchmark]\n",
    "        \n",
    "        for variant in bench_data['model_variant'].unique():\n",
    "            variant_data = bench_data[bench_data['model_variant'] == variant]\n",
    "            \n",
    "            for method in variant_data['method'].unique():\n",
    "                method_data = variant_data[variant_data['method'] == method]\n",
    "                \n",
    "                # Calculate average recovery\n",
    "                avg_recovery = method_data['recovery_pct'].mean()\n",
    "                \n",
    "                # Count metrics that improved (negative change for manipulation metrics is good)\n",
    "                improved_metrics = (method_data['absolute_change'] < 0).sum()\n",
    "                total_metrics = len(method_data)\n",
    "                \n",
    "                # Average absolute change\n",
    "                avg_abs_change = method_data['absolute_change'].mean()\n",
    "                avg_pct_change = method_data['percent_change'].mean()\n",
    "                \n",
    "                summary_data.append({\n",
    "                    'Benchmark': benchmark.replace('_', ' ').title(),\n",
    "                    'Model Variant': variant.upper(),\n",
    "                    'Method': method.replace('_', ' ').title(),\n",
    "                    'Best Ratio': method_data['best_ratio'].iloc[0],\n",
    "                    'Avg Recovery %': avg_recovery,\n",
    "                    'Improved Metrics': f\"{improved_metrics}/{total_metrics}\",\n",
    "                    'Avg Absolute Change': avg_abs_change,\n",
    "                    'Avg % Change': avg_pct_change\n",
    "                })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Save\n",
    "    summary_df.to_csv('tables/unlearning_summary.csv', index=False)\n",
    "    print(\"\\nSaved summary table to: tables/unlearning_summary.csv\")\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ff8a2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATING SUMMARY COMPARISON TABLE\n",
      "================================================================================\n",
      "\n",
      "Saved summary table to: tables/unlearning_summary.csv\n",
      "\n",
      "Summary Comparison:\n",
      "         Benchmark Model Variant          Method  Best Ratio  Avg Recovery % Improved Metrics  Avg Absolute Change  Avg % Change\n",
      "Benchmark Honeypot      FINETUNE     First Order        0.10       52.764891             4/15            -0.044574      3.018421\n",
      "Benchmark Honeypot      FINETUNE Gradient Ascent        0.05      -26.317381             4/15             0.009805      0.850884\n",
      "Benchmark Honeypot        FROZEN     First Order        0.20      191.770218             3/15             0.112991     95.600925\n",
      "Benchmark Honeypot        FROZEN Gradient Ascent        0.01       -0.482228            11/15            -0.002316      0.096687\n",
      "   Benchmark Mixed      FINETUNE     First Order        0.10     -109.877799            10/15            -0.133312     -1.919125\n",
      "   Benchmark Mixed      FINETUNE Gradient Ascent        0.05       58.334317             4/15             0.012673      0.322540\n",
      "   Benchmark Mixed        FROZEN     First Order        0.20       61.229350             4/15             0.057699    155.081941\n",
      "   Benchmark Mixed        FROZEN Gradient Ascent        0.01        0.027898             7/15            -0.000685      0.063168\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING SUMMARY COMPARISON TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_comparison = create_summary_comparison_table(impact_df)\n",
    "print(\"\\nSummary Comparison:\")\n",
    "print(summary_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e47313",
   "metadata": {},
   "source": [
    "## 14. Create Metric-Specific Impact Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74c98df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metric_impact_tables(impact_df):\n",
    "    \"\"\"Create separate tables for each metric showing impact across methods, benchmarks, and variants\"\"\"\n",
    "    \n",
    "    metrics = impact_df['metric'].unique()\n",
    "    \n",
    "    for metric in metrics:\n",
    "        metric_data = impact_df[impact_df['metric'] == metric].copy()\n",
    "        \n",
    "        # Pivot table for easy comparison\n",
    "        pivot_table = metric_data.pivot_table(\n",
    "            index=['benchmark', 'model_variant', 'method'],\n",
    "            values=['clean_value', 'poisoned_value', 'unlearned_value', \n",
    "                   'absolute_change', 'percent_change', 'recovery_pct'],\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Format names\n",
    "        pivot_table['benchmark'] = pivot_table['benchmark'].str.replace('_', ' ').str.title()\n",
    "        pivot_table['model_variant'] = pivot_table['model_variant'].str.upper()\n",
    "        pivot_table['method'] = pivot_table['method'].str.replace('_', ' ').str.title()\n",
    "        \n",
    "        # Save\n",
    "        filename = f\"tables/impact_{metric.replace('@', '_at_').replace('/', '_')}.csv\"\n",
    "        pivot_table.to_csv(filename, index=False)\n",
    "        print(f\"Saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "809af9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATING METRIC-SPECIFIC IMPACT TABLES\n",
      "================================================================================\n",
      "Saved: tables/impact_AUC.csv\n",
      "Saved: tables/impact_MRR.csv\n",
      "Saved: tables/impact_NDCG_at_5.csv\n",
      "Saved: tables/impact_NDCG_at_10.csv\n",
      "Saved: tables/impact_Recall_at_5.csv\n",
      "Saved: tables/impact_Recall_at_10.csv\n",
      "Saved: tables/impact_MC_at_5.csv\n",
      "Saved: tables/impact_MC_at_10.csv\n",
      "Saved: tables/impact_MC_at_20.csv\n",
      "Saved: tables/impact_avg_fake_in_top_10.csv\n",
      "Saved: tables/impact_avg_fake_in_top_20.csv\n",
      "Saved: tables/impact_users_with_fake_pct_top_10.csv\n",
      "Saved: tables/impact_users_with_fake_pct_top_20.csv\n",
      "Saved: tables/impact_avg_fake_ratio_top_10.csv\n",
      "Saved: tables/impact_avg_fake_ratio_top_20.csv\n",
      "\n",
      "All metric-specific tables created!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING METRIC-SPECIFIC IMPACT TABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "create_metric_impact_tables(impact_df)\n",
    "\n",
    "print(\"\\nAll metric-specific tables created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082c5c6",
   "metadata": {},
   "source": [
    "## 15. Direct Finetune vs Frozen Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57c71ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetune_vs_frozen_comparison(impact_df, output_dir='plots'):\n",
    "    \"\"\"Create comparison visualizations showing finetune vs frozen side-by-side\"\"\"\n",
    "    \n",
    "    benchmarks = impact_df['benchmark'].unique()\n",
    "    methods = impact_df['method'].unique()\n",
    "    \n",
    "    for benchmark in benchmarks:\n",
    "        bench_data = impact_df[impact_df['benchmark'] == benchmark]\n",
    "        \n",
    "        if len(bench_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        for method in methods:\n",
    "            method_data = bench_data[bench_data['method'] == method]\n",
    "            \n",
    "            if len(method_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Get finetune and frozen data\n",
    "            finetune_data = method_data[method_data['model_variant'] == 'finetune'].sort_values('metric')\n",
    "            frozen_data = method_data[method_data['model_variant'] == 'frozen'].sort_values('metric')\n",
    "            \n",
    "            if len(finetune_data) == 0 or len(frozen_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Make sure both have the same metrics in the same order\n",
    "            common_metrics = list(set(finetune_data['metric'].tolist()) & set(frozen_data['metric'].tolist()))\n",
    "            if len(common_metrics) == 0:\n",
    "                continue\n",
    "            \n",
    "            finetune_data = finetune_data[finetune_data['metric'].isin(common_metrics)].sort_values('metric')\n",
    "            frozen_data = frozen_data[frozen_data['metric'].isin(common_metrics)].sort_values('metric')\n",
    "            \n",
    "            # Create comparison plot\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "            \n",
    "            # Plot 1: Recovery percentage comparison\n",
    "            metrics = finetune_data['metric'].tolist()\n",
    "            x = np.arange(len(metrics))\n",
    "            width = 0.35\n",
    "            \n",
    "            finetune_recovery = finetune_data['recovery_pct'].values\n",
    "            frozen_recovery = frozen_data['recovery_pct'].values\n",
    "            \n",
    "            bars1 = ax1.bar(x - width/2, finetune_recovery, width, \n",
    "                           label='Finetune', alpha=0.8, color='steelblue')\n",
    "            bars2 = ax1.bar(x + width/2, frozen_recovery, width, \n",
    "                           label='Frozen', alpha=0.8, color='darkorange')\n",
    "            \n",
    "            ax1.set_xlabel('Metrics', fontsize=11, fontweight='bold')\n",
    "            ax1.set_ylabel('Recovery Percentage (%)', fontsize=11, fontweight='bold')\n",
    "            ax1.set_title(f'Recovery % Comparison: {method.replace(\"_\", \" \").title()}', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "            ax1.set_xticks(x)\n",
    "            ax1.set_xticklabels(metrics, rotation=45, ha='right', fontsize=9)\n",
    "            ax1.axhline(y=100, color='green', linestyle='--', linewidth=1, alpha=0.5, label='100% Recovery')\n",
    "            ax1.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "            ax1.legend()\n",
    "            ax1.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar in bars1:\n",
    "                height = bar.get_height()\n",
    "                if height is not None and not np.isnan(height):\n",
    "                    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{height:.1f}%',\n",
    "                           ha='center', va='bottom' if height >= 0 else 'top', fontsize=8)\n",
    "            \n",
    "            for bar in bars2:\n",
    "                height = bar.get_height()\n",
    "                if height is not None and not np.isnan(height):\n",
    "                    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{height:.1f}%',\n",
    "                           ha='center', va='bottom' if height >= 0 else 'top', fontsize=8)\n",
    "            \n",
    "            # Plot 2: Absolute change comparison\n",
    "            finetune_change = finetune_data['absolute_change'].values\n",
    "            frozen_change = frozen_data['absolute_change'].values\n",
    "            \n",
    "            bars3 = ax2.bar(x - width/2, finetune_change, width, \n",
    "                           label='Finetune', alpha=0.8, color='steelblue')\n",
    "            bars4 = ax2.bar(x + width/2, frozen_change, width, \n",
    "                           label='Frozen', alpha=0.8, color='darkorange')\n",
    "            \n",
    "            ax2.set_xlabel('Metrics', fontsize=11, fontweight='bold')\n",
    "            ax2.set_ylabel('Absolute Change from Poisoned', fontsize=11, fontweight='bold')\n",
    "            ax2.set_title(f'Absolute Change Comparison: {method.replace(\"_\", \" \").title()}', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "            ax2.set_xticks(x)\n",
    "            ax2.set_xticklabels(metrics, rotation=45, ha='right', fontsize=9)\n",
    "            ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
    "            ax2.legend()\n",
    "            ax2.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar in bars3:\n",
    "                height = bar.get_height()\n",
    "                if height is not None and not np.isnan(height):\n",
    "                    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{height:.3f}',\n",
    "                           ha='center', va='bottom' if height >= 0 else 'top', fontsize=8)\n",
    "            \n",
    "            for bar in bars4:\n",
    "                height = bar.get_height()\n",
    "                if height is not None and not np.isnan(height):\n",
    "                    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{height:.3f}',\n",
    "                           ha='center', va='bottom' if height >= 0 else 'top', fontsize=8)\n",
    "            \n",
    "            plt.suptitle(f'{benchmark.replace(\"_\", \" \").title()} - Finetune vs Frozen Comparison',\n",
    "                        fontsize=14, fontweight='bold', y=1.02)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            filename = f\"{output_dir}/finetune_vs_frozen_{method}_{benchmark}.png\"\n",
    "            plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Saved comparison: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0aa6ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATING FINETUNE VS FROZEN COMPARISON PLOTS\n",
      "================================================================================\n",
      "Saved comparison: plots/finetune_vs_frozen_first_order_benchmark_honeypot.png\n",
      "Saved comparison: plots/finetune_vs_frozen_gradient_ascent_benchmark_honeypot.png\n",
      "Saved comparison: plots/finetune_vs_frozen_first_order_benchmark_mixed.png\n",
      "Saved comparison: plots/finetune_vs_frozen_gradient_ascent_benchmark_mixed.png\n",
      "\n",
      "All finetune vs frozen comparison plots created!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING FINETUNE VS FROZEN COMPARISON PLOTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "create_finetune_vs_frozen_comparison(impact_df)\n",
    "\n",
    "print(\"\\nAll finetune vs frozen comparison plots created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21537eb",
   "metadata": {},
   "source": [
    "## 16. Analysis Complete - Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7ef313d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GENERATED FILES SUMMARY\n",
      "================================================================================\n",
      "\n",
      "📊 TABLES (in 'tables/' directory):\n",
      "  Core Metric Tables:\n",
      "    - manipulation_detection_metrics.csv\n",
      "    - average_fake_items.csv\n",
      "    - user_coverage_metrics.csv\n",
      "    - fake_ratio_metrics.csv\n",
      "    - performance_metrics.csv\n",
      "\n",
      "  Impact Analysis Tables:\n",
      "    - unlearning_impact_analysis.csv (detailed impact for all metrics)\n",
      "    - unlearning_summary.csv (high-level comparison)\n",
      "    - impact_[metric_name].csv (one table per metric)\n",
      "\n",
      "📈 PLOTS (in 'plots/' directory):\n",
      "  Individual Metric Plots:\n",
      "    - [metric]_[benchmark].png (line plots comparing finetune vs frozen)\n",
      "\n",
      "  Combined Visualizations:\n",
      "    - combined_manipulation_detection_[benchmark].png\n",
      "    - combined_average_fake_items_[benchmark].png\n",
      "    - combined_user_coverage_[benchmark].png\n",
      "    - combined_fake_ratios_[benchmark].png\n",
      "\n",
      "  Impact Visualizations:\n",
      "    - impact_recovery_[benchmark].png (recovery bars for finetune & frozen)\n",
      "    - finetune_vs_frozen_[method]_[benchmark].png (direct comparison plots)\n",
      "\n",
      "================================================================================\n",
      "KEY FINDINGS\n",
      "================================================================================\n",
      "\n",
      "🔍 Overall Unlearning Performance:\n",
      "\n",
      "  Benchmark Honeypot:\n",
      "\n",
      "    FINETUNE:\n",
      "      First Order (ratio=0.1):\n",
      "        - Average Recovery: 52.76%\n",
      "        - Metrics Improved: 4/15\n",
      "        - Average Change: 3.02%\n",
      "      Gradient Ascent (ratio=0.05):\n",
      "        - Average Recovery: -26.32%\n",
      "        - Metrics Improved: 4/15\n",
      "        - Average Change: 0.85%\n",
      "\n",
      "    FROZEN:\n",
      "      First Order (ratio=0.2):\n",
      "        - Average Recovery: 191.77%\n",
      "        - Metrics Improved: 3/15\n",
      "        - Average Change: 95.60%\n",
      "      Gradient Ascent (ratio=0.01):\n",
      "        - Average Recovery: -0.48%\n",
      "        - Metrics Improved: 11/15\n",
      "        - Average Change: 0.10%\n",
      "\n",
      "  Benchmark Mixed:\n",
      "\n",
      "    FINETUNE:\n",
      "      First Order (ratio=0.1):\n",
      "        - Average Recovery: -109.88%\n",
      "        - Metrics Improved: 10/15\n",
      "        - Average Change: -1.92%\n",
      "      Gradient Ascent (ratio=0.05):\n",
      "        - Average Recovery: 58.33%\n",
      "        - Metrics Improved: 4/15\n",
      "        - Average Change: 0.32%\n",
      "\n",
      "    FROZEN:\n",
      "      First Order (ratio=0.2):\n",
      "        - Average Recovery: 61.23%\n",
      "        - Metrics Improved: 4/15\n",
      "        - Average Change: 155.08%\n",
      "      Gradient Ascent (ratio=0.01):\n",
      "        - Average Recovery: 0.03%\n",
      "        - Metrics Improved: 7/15\n",
      "        - Average Change: 0.06%\n",
      "\n",
      "================================================================================\n",
      "\n",
      "✅ To view results:\n",
      "  1. Check 'tables/' directory for detailed CSV files\n",
      "  2. Check 'plots/' directory for visualizations\n",
      "  3. Review 'unlearning_impact_analysis.csv' for complete impact analysis\n",
      "  4. Review 'unlearning_summary.csv' for high-level comparison\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATED FILES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 TABLES (in 'tables/' directory):\")\n",
    "print(\"  Core Metric Tables:\")\n",
    "print(\"    - manipulation_detection_metrics.csv\")\n",
    "print(\"    - average_fake_items.csv\")\n",
    "print(\"    - user_coverage_metrics.csv\")\n",
    "print(\"    - fake_ratio_metrics.csv\")\n",
    "print(\"    - performance_metrics.csv\")\n",
    "print(\"\\n  Impact Analysis Tables:\")\n",
    "print(\"    - unlearning_impact_analysis.csv (detailed impact for all metrics)\")\n",
    "print(\"    - unlearning_summary.csv (high-level comparison)\")\n",
    "print(\"    - impact_[metric_name].csv (one table per metric)\")\n",
    "\n",
    "print(\"\\n📈 PLOTS (in 'plots/' directory):\")\n",
    "print(\"  Individual Metric Plots:\")\n",
    "print(\"    - [metric]_[benchmark].png (line plots comparing finetune vs frozen)\")\n",
    "print(\"\\n  Combined Visualizations:\")\n",
    "print(\"    - combined_manipulation_detection_[benchmark].png\")\n",
    "print(\"    - combined_average_fake_items_[benchmark].png\")\n",
    "print(\"    - combined_user_coverage_[benchmark].png\")\n",
    "print(\"    - combined_fake_ratios_[benchmark].png\")\n",
    "print(\"\\n  Impact Visualizations:\")\n",
    "print(\"    - impact_recovery_[benchmark].png (recovery bars for finetune & frozen)\")\n",
    "print(\"    - finetune_vs_frozen_[method]_[benchmark].png (direct comparison plots)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate some key statistics\n",
    "if len(impact_df) > 0:\n",
    "    print(\"\\n🔍 Overall Unlearning Performance:\")\n",
    "    \n",
    "    for benchmark in benchmarks_to_plot:\n",
    "        bench_data = impact_df[impact_df['benchmark'] == benchmark]\n",
    "        if len(bench_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n  {benchmark.replace('_', ' ').title()}:\")\n",
    "        \n",
    "        for variant in ['finetune', 'frozen']:\n",
    "            variant_data = bench_data[bench_data['model_variant'] == variant]\n",
    "            if len(variant_data) == 0:\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n    {variant.upper()}:\")\n",
    "            \n",
    "            for method in variant_data['method'].unique():\n",
    "                method_data = variant_data[variant_data['method'] == method]\n",
    "                avg_recovery = method_data['recovery_pct'].mean()\n",
    "                best_ratio = method_data['best_ratio'].iloc[0]\n",
    "                \n",
    "                improved_count = (method_data['absolute_change'] < 0).sum()\n",
    "                total_count = len(method_data)\n",
    "                \n",
    "                print(f\"      {method.replace('_', ' ').title()} (ratio={best_ratio}):\")\n",
    "                print(f\"        - Average Recovery: {avg_recovery:.2f}%\")\n",
    "                print(f\"        - Metrics Improved: {improved_count}/{total_count}\")\n",
    "                print(f\"        - Average Change: {method_data['percent_change'].mean():.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n✅ To view results:\")\n",
    "print(\"  1. Check 'tables/' directory for detailed CSV files\")\n",
    "print(\"  2. Check 'plots/' directory for visualizations\")\n",
    "print(\"  3. Review 'unlearning_impact_analysis.csv' for complete impact analysis\")\n",
    "print(\"  4. Review 'unlearning_summary.csv' for high-level comparison\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a83cba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plm4newsrs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
