# ============================================
# GRADIENT ASCENT UNLEARNING (RATIO MODE)
# ============================================
# USE CASE: Development / Multi-ratio & multi-trial experiments
# Loss maximization: θ_new = θ + α · ∇L(Z_forget, θ)
# Based on: "Knowledge Unlearning for Mitigating Privacy Risks in LMs"
# ============================================

# Method
method: "gradient_ascent"

# Data mode: RATIO (for experiments)
mode: "ratio"

# Ratio mode: Directory containing pre-generated splits
unlearning_splits_dir: "data/politifact/unlearning_splits/ratio_0_05"
ratio: 0.05
trial_idx: 0

use_label_correction: false  # Gradient ascent doesn't use label correction

# Removal strategy for creating splits
removal_strategy: "fake_positive_history"

# ============================================
# UNLEARNING PARAMETERS
# ============================================
# Learning rate for gradient ascent
learning_rate: 0.01

# Number of gradient ascent iterations
num_steps: 10

# Gradient clipping
gradient_clip_val: 1.0

# Retain regularization
use_retain_regularization: false
retain_weight: 0.1

# ============================================
# EVALUATION
# ============================================
evaluate_forget_quality: true
evaluate_utility: true
evaluate_efficiency: true
benchmark_filter: null

# ============================================
# OUTPUT
# ============================================
save_unlearned_model: true
output_dir: null  # Auto-generated: ratio_{ratio}/trial_{trial_idx}/

# ============================================
# COMPARISON & CACHING
# ============================================
compare_with_original: true
cache_original_predictions: true

# ============================================
# REPRODUCIBILITY
# ============================================
seed: 42